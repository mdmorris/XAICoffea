{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "\n",
    "import keras\n",
    "import keras.backend\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras.utils\n",
    "\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import math\n",
    "import time\n",
    "import h5py\n",
    "import sklearn\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import os\n",
    "\n",
    "#print('TensorFlow Version {}'.format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetPreProcessedArrays(totalVar, nXvar):\n",
    "    \n",
    "    setday = '072220'\n",
    "    \n",
    "    file_extension = str(totalVar)+'var_'+str(nXvar)+'Xvar_'+'normalized.npz'\n",
    "    \n",
    "    testname    = 'PreProcessing/'+setday+'/test_variables_'+file_extension\n",
    "    trainname   = 'PreProcessing/'+setday+'/train_variables_'+file_extension\n",
    "    examplename = 'PreProcessing/'+setday+'/example_variables_'+file_extension\n",
    "    \n",
    "    testvarFile    = np.load(testname)\n",
    "    trainvarFile   = np.load(trainname)\n",
    "    examplevarFile = np.load(examplename)\n",
    "    \n",
    "    testlabels    = testvarFile['labels']\n",
    "    trainlabels   = trainvarFile['labels']\n",
    "    examplelabels = examplevarFile['labels']\n",
    "    \n",
    "    test_variables    = [testvarFile[key] for key in testvarFile if (not 'label' in key and not 'vari' in key)]\n",
    "    train_variables   = [trainvarFile[key] for key in trainvarFile if (not 'label' in key and not 'vari' in key)]\n",
    "    example_variables = [examplevarFile[key] for key in examplevarFile if (not 'label' in key and not 'vari' in key)]\n",
    "    \n",
    "    return test_variables, train_variables, example_variables, testlabels, trainlabels, examplelabels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File variables:\n",
      "__17var__jetconstPt_log__jetconstEta_abs__jetconstE_log__jetconstPt_Jetlog__charge__isEle__isPho__isMuon__isCh__isNh__delta_eta__delta_phi__deltaR_jet__deltaR_subjet0__deltaR_subjet1__dxy__dz\n",
      "\n"
     ]
    }
   ],
   "source": [
    "variables = []\n",
    "expertVariables = []\n",
    "# expertVariables = ['chMult',\n",
    "#                    'jetpull',\n",
    "#                    'tau1_b05',\n",
    "#                    'tau2_b05',\n",
    "#                    'tau3_b05',\n",
    "#                    'tau1_sd_b05',\n",
    "#                    'tau2_sd_b05',\n",
    "#                    'tau3_sd_b05',\n",
    "#                    'tau1_b10',\n",
    "#                    'tau2_b10',\n",
    "#                    'tau3_b10',\n",
    "#                    'tau1_sd_b10',\n",
    "#                    'tau2_sd_b10',\n",
    "#                    'tau3_sd_b10',\n",
    "#                    'tau1_b15',\n",
    "#                    'tau2_b15',\n",
    "#                    'tau3_b15',\n",
    "#                    'tau1_sd_b15',\n",
    "#                    'tau2_sd_b15',\n",
    "#                    'tau3_sd_b15',\n",
    "#                    'tau1_b20',\n",
    "#                    'tau2_b20',\n",
    "#                    'tau3_b20',\n",
    "#                    'tau1_sd_b20',\n",
    "#                    'tau2_sd_b20',\n",
    "#                    'tau3_sd_b20',\n",
    "#                    'jetMass',\n",
    "#                    'jetMassSD',\n",
    "#                   ]\n",
    "variables = ['jetconstEta_abs',\n",
    "                'jetconstE_log',\n",
    "                'jetconstPt_Jetlog',\n",
    "                'charge',\n",
    "                'isEle',\n",
    "                'isPho',\n",
    "                'isMuon',\n",
    "                'isCh',\n",
    "                'isNh',\n",
    "                'delta_eta',\n",
    "                'delta_phi',\n",
    "                'deltaR_jet',\n",
    "                'deltaR_subjet0',\n",
    "                'deltaR_subjet1',\n",
    "                'dxy',\n",
    "                'dz',\n",
    "               ]\n",
    "\n",
    "\n",
    "\n",
    "allVariables = ['jetconstPt_log'] + variables + expertVariables\n",
    "nVar = len(variables + expertVariables)\n",
    "variables_in_plots = '__'+str(nVar+1)+'var__jetconstPt_log'\n",
    "\n",
    "totalVar = len(allVariables)\n",
    "nXvar = len(expertVariables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1DCNN_2ptc_norm_17var_0Xvar_1.h5\n"
     ]
    }
   ],
   "source": [
    "modelN = 1\n",
    "patience = 2\n",
    "model_name = '1DCNN_'+str(patience)+'ptc_norm_'+str(totalVar)+'var_'+str(nXvar)+'Xvar_'+str(modelN)+'.h5'\n",
    "\n",
    "if(os.path.isfile('model/'+model_name)):\n",
    "    modelN += 1\n",
    "    model_name = '1DCNN_'+str(patience)+'ptc_norm_'+str(totalVar)+'var_'+str(nXvar)+'Xvar_'+str(modelN)+'.h5\n",
    "\n",
    "\n",
    "print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_variables, train_variables, example_variables, \\\n",
    "testlabels, trainlabels, example_labels = GetPreProcessedArrays(totalVar, nXvar)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing variables\n",
      "(441390, 20, 1)\n",
      "(441390, 20, 1)\n",
      "(441390, 20, 1)\n",
      "(441390, 20, 1)\n",
      "(441390, 20, 1)\n",
      "(441390, 20, 1)\n",
      "(441390, 20, 1)\n",
      "(441390, 20, 1)\n",
      "(441390, 20, 1)\n",
      "(441390, 20, 1)\n",
      "(441390, 20, 1)\n",
      "(441390, 20, 1)\n",
      "(441390, 20, 1)\n",
      "(441390, 20, 1)\n",
      "(441390, 20, 1)\n",
      "(441390, 20, 1)\n",
      "(441390, 20, 1)\n",
      "\n",
      "training variables\n",
      "(1103470, 20, 1)\n",
      "(1103470, 20, 1)\n",
      "(1103470, 20, 1)\n",
      "(1103470, 20, 1)\n",
      "(1103470, 20, 1)\n",
      "(1103470, 20, 1)\n",
      "(1103470, 20, 1)\n",
      "(1103470, 20, 1)\n",
      "(1103470, 20, 1)\n",
      "(1103470, 20, 1)\n",
      "(1103470, 20, 1)\n",
      "(1103470, 20, 1)\n",
      "(1103470, 20, 1)\n",
      "(1103470, 20, 1)\n",
      "(1103470, 20, 1)\n",
      "(1103470, 20, 1)\n",
      "(1103470, 20, 1)\n",
      "\n",
      "example variables\n",
      "(3679, 20, 1)\n",
      "(3679, 20, 1)\n",
      "(3679, 20, 1)\n",
      "(3679, 20, 1)\n",
      "(3679, 20, 1)\n",
      "(3679, 20, 1)\n",
      "(3679, 20, 1)\n",
      "(3679, 20, 1)\n",
      "(3679, 20, 1)\n",
      "(3679, 20, 1)\n",
      "(3679, 20, 1)\n",
      "(3679, 20, 1)\n",
      "(3679, 20, 1)\n",
      "(3679, 20, 1)\n",
      "(3679, 20, 1)\n",
      "(3679, 20, 1)\n",
      "(3679, 20, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('testing variables')\n",
    "for test_var in test_variables:\n",
    "    print(test_var.shape)\n",
    "#print(testlabels.shape)\n",
    "print()\n",
    "\n",
    "print('training variables')\n",
    "for train_var in train_variables:\n",
    "    print(train_var.shape)\n",
    "#print(trainlabels.shape)\n",
    "print()\n",
    "\n",
    "print('example variables')\n",
    "for ex_var in example_variables:\n",
    "    print(ex_var.shape)\n",
    "#print(example_labels.shape)    \n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## OLD MODEL WITHOUT EXPERT VARIABLES ## \n",
    "\n",
    "# def build_model(n):\n",
    "    \n",
    "#     inpts = []\n",
    "#     xlayers = []\n",
    "#     for i in range(n):\n",
    "#         inpt = layers.Input(shape = (20,1))\n",
    "        \n",
    "#         x = layers.Conv1D(64, 3, padding = 'same', activation='relu')(inpt)\n",
    "#         x = layers.Conv1D(64, 1, padding = 'same', activation='relu')(x)\n",
    "#         x = layers.MaxPool1D(2)(x)\n",
    "#         x = layers.Conv1D(32, 3, padding = 'same', activation='relu')(x)\n",
    "#         x = layers.Conv1D(32, 1, padding = 'same', activation='relu')(x)\n",
    "#         x = layers.MaxPool1D()(x)\n",
    "#         x = layers.Flatten()(x)\n",
    "        \n",
    "#         inpts.append(inpt)\n",
    "#         xlayers.append(x)\n",
    "    \n",
    "#     if(n > 1):\n",
    "#         x = layers.concatenate(inputs=xlayers, axis=-1)\n",
    "\n",
    "#     x = layers.Dense(64, activation='relu')(x)\n",
    "#     output = layers.Dense(2, activation='softmax')(x)\n",
    "#     model = models.Model(inputs=inpts, outputs=output)\n",
    "#     model.compile(loss='categorical_crossentropy',\n",
    "#                 optimizer='adam',\n",
    "#                 metrics=['categorical_crossentropy', 'accuracy'])\n",
    "    \n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n, nex):\n",
    "    \n",
    "    inpts = []\n",
    "    xaugs = []\n",
    "    xlayers = []\n",
    "    \n",
    "    # loop over all input variables\n",
    "    for i in range(n):\n",
    "        \n",
    "        # particle list inputs \n",
    "        if(i < n-nex):\n",
    "\n",
    "            inpt = layers.Input(shape = (20,1))\n",
    "\n",
    "            x = layers.Conv1D(64, 3, padding = 'same', activation='relu')(inpt)\n",
    "            x = layers.Conv1D(64, 1, padding = 'same', activation='relu')(x)\n",
    "            x = layers.MaxPool1D(2)(x)\n",
    "            x = layers.Conv1D(32, 3, padding = 'same', activation='relu')(x)\n",
    "            x = layers.Conv1D(32, 1, padding = 'same', activation='relu')(x)\n",
    "            x = layers.MaxPool1D()(x)\n",
    "            x1 = layers.Flatten()(x)\n",
    "\n",
    "            inpts.append(inpt)\n",
    "            xlayers.append(x1)\n",
    "        \n",
    "        \n",
    "        # expert variable inputs \n",
    "        elif((nex > 0)):\n",
    "\n",
    "            inpt = layers.Input(shape = (1,))\n",
    "            xaugs.append(inpt)\n",
    "    \n",
    "    #concatenation of particle list inputs with expert variable inputs\n",
    "    if(n > 1):\n",
    "        x = layers.concatenate(inputs=xlayers+xaugs, axis=-1)\n",
    "\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    \n",
    "    output = layers.Dense(2, activation='softmax')(x) \n",
    "    model = models.Model(inputs=inpts+xaugs, outputs=output)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                optimizer='adam',\n",
    "                metrics=['categorical_crossentropy', 'accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N Particle List Variables: 17\n",
      "N Expert Variables: 0\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "Ntotal = len(example_variables)\n",
    "Nexpert = len(expertVariables)\n",
    "\n",
    "print('N Particle List Variables:', Ntotal-Nexpert)\n",
    "print('N Expert Variables:', Nexpert)\n",
    "\n",
    "CNN = build_model( Ntotal, Nexpert )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for lay in CNN.layers:\n",
    "#     print(lay.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.47489545 0.5251045 ]\n",
      " [0.47863865 0.52136135]\n",
      " [0.48123366 0.51876634]\n",
      " ...\n",
      " [0.4919332  0.5080668 ]\n",
      " [0.4707355  0.52926445]\n",
      " [0.47814685 0.5218531 ]]\n",
      "[0.694931804744988, 0.694931804744988, 0.49986409350366945]\n"
     ]
    }
   ],
   "source": [
    "example_result = CNN.predict(x = example_variables)\n",
    "results = CNN.evaluate(x = example_variables, y = example_labels, verbose = 0)\n",
    "print(example_result)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "circleCNN = build_model( Ntotal, Nexpert )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3679/3679 [==============================] - 1s 301us/step\n",
      "[[0.48318654 0.5168135 ]\n",
      " [0.47947428 0.5205257 ]\n",
      " [0.51798624 0.48201382]\n",
      " ...\n",
      " [0.523898   0.47610196]\n",
      " [0.48380938 0.51619065]\n",
      " [0.4784424  0.5215576 ]]\n",
      "[0.6942063004110585, 0.6942063004110585, 0.4917097034970196]\n"
     ]
    }
   ],
   "source": [
    "example_result = circleCNN.predict(x = example_variables)\n",
    "results = circleCNN.evaluate(x = example_variables, y = example_labels)\n",
    "print(example_result)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.83209, saving model to model/1DCNN_2ptc_norm_17var_0Xvar_1.h5\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.83209\n"
     ]
    }
   ],
   "source": [
    "class PrintDot(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        if epoch % 100 == 0:\n",
    "            print('')\n",
    "        print('.', end='')\n",
    "    \n",
    "checkpoint_path = 'model/'+model_name\n",
    "if not os.path.exists(\"model\"):\n",
    "    os.mkdir(\"model\")\n",
    "\n",
    "# Create checkpoint callback\n",
    "# cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, \n",
    "#                                                  save_best_only=True,\n",
    "#                                                  verbose=1)\n",
    "model_checkpoint = keras.callbacks.ModelCheckpoint(checkpoint_path, monitor='val_loss', \n",
    "                                   verbose=1, save_best_only=True, \n",
    "                                   save_weights_only=False, mode='auto', \n",
    "                                   period=1)    \n",
    "EPOCHS = 50\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience)\n",
    "\n",
    "toc = time.time()\n",
    "history = circleCNN.fit(\n",
    "  train_variables, trainlabels,\n",
    "  epochs=EPOCHS, validation_split = 0.2, verbose = 0,\n",
    "  callbacks=[early_stop, model_checkpoint])\n",
    "tic = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = tic - toc\n",
    "print('Elapsed Time: {0:0.1f} h {1:0.1f} min {2:0.2f} sec'.format(delta // 3600, delta % 3600 // 60, delta % 3600 % 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    hist['epoch'] = history.epoch\n",
    "    \n",
    "    mask=slice(0,None)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.plot(hist['epoch'][mask], hist['loss'][mask],\n",
    "             label='Loss')\n",
    "    plt.plot(hist['epoch'][mask], hist['val_loss'][mask],\n",
    "             label = 'Validation Loss')\n",
    "\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.plot(hist['epoch'], hist['acc'], color='C3',\n",
    "             label='Accuracy')\n",
    "    plt.plot(hist['epoch'], hist['val_acc'], color='C4',\n",
    "             label = 'Val Accuracy')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_history(history)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!ls -t model | head -1\n",
    "best_model = keras.models.load_model('model/'+model_name)\n",
    "best_model.summary()\n",
    "results = best_model.evaluate(test_variables, testlabels)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC\n",
    "\n",
    "predict = best_model.predict(test_variables)\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.dpi'] = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indqcd = np.argwhere(testlabels[:,1] == 0)\n",
    "indz  = np.where(testlabels[:,1] == 1)\n",
    "\n",
    "#hist_, bin_edges_ = np.histogram(predict[indqcd])\n",
    "bins = np.linspace(0,1,10)\n",
    "\n",
    "plt.hist([1-predict[indz, 1].flatten(),predict[indqcd, 0].flatten()],histtype='stepfilled', color=['C1','C0'], label = ['QCD', 'ZZ'], alpha=0.5)\n",
    "plt.legend()\n",
    "plt.title('Predictions')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Prediction')\n",
    "plt.ylabel('Counts')\n",
    "plt.xlim([0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(testlabels[:,0], predict[:,0])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, lw=2, color='b', label='auc = %.3f' % (roc_auc))\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='k', label='random chance')\n",
    "plt.xlim([0, 1.0])\n",
    "plt.ylim([0, 1.0])\n",
    "plt.xlabel('false positive rate')\n",
    "plt.ylabel('true positive rate')\n",
    "plt.title('receiver operating curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('ROC_'+str(totalVar)+'_flat.png')\n",
    "np.savez('ROC_'+str(totalVar)+'_flat', false_pos_rate=fpr, true_pos_rate=tpr, auc=roc_auc, label=str(nVar+1)+'var')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
