{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "#tf.enable_eager_execution()\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "\n",
    "import keras\n",
    "import keras.backend\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras.utils\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "from scipy import stats,special\n",
    "\n",
    "from matplotlib.colors import LogNorm\n",
    "from matplotlib import gridspec\n",
    "import math\n",
    "import time\n",
    "import h5py\n",
    "import sklearn\n",
    "from sklearn.utils import shuffle\n",
    "from awkward import JaggedArray, MaskedArray\n",
    "\n",
    "# innvestigate for lrp\n",
    "import innvestigate\n",
    "import innvestigate.utils as iutils\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('/mnt/users/morris35/results/CNNsimple/Python')\n",
    "\n",
    "from networkBuilder import *\n",
    "\n",
    "print('TensorFlow Version {}'.format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'legend.fontsize': 'x-large',\n",
    "         'axes.labelsize': 'x-large',\n",
    "         'axes.titlesize':'x-large',\n",
    "         'font.family':'serif',\n",
    "         'xtick.labelsize':'x-large',\n",
    "         'ytick.labelsize':'x-large',\n",
    "         'figure.facecolor':'white',\n",
    "         'axes.grid':True,\n",
    "         'grid.alpha':1.0}\n",
    "plt.rcParams.update(params)\n",
    "plt.style.context('default')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sig = np.load('/mnt/data/ml/PreProcessing/ShowJets_test_Zbb_exts_msd50to150_v2.npz')\n",
    "test_bkg = np.load('/mnt/data/ml/PreProcessing/ShowJets_test_QCD_exts_msd50to150_v2.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = [\n",
    "    'Particle List Only',\n",
    "    'Particle List Only no flavor',\n",
    "    'Particle List + all XAUGS',\n",
    "    'Particle List + XAUGS no flavor',\n",
    "    'Particle List + 5 XAUGS',\n",
    "    'XAUGS only',\n",
    "    'XAUGS only no flavor',\n",
    "]\n",
    "\n",
    "option = 'Particle List Only'\n",
    "model_name = '1DCNN_plist_1.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model and Get Test Data arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = keras.models.load_model('model/'+model_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# rename dense layers for softmax layer removal function later\n",
    "\n",
    "layer_i = 1\n",
    "\n",
    "for layer in best_model.layers:\n",
    "    if('dense' in layer.name):\n",
    "        layer.name = 'renamed_dense_layer'+str(layer_i)\n",
    "        layer_i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_five_xaugs = [\n",
    "    'jetMassSD',\n",
    "    'tau3_b10',\n",
    "    'tau3_sd_b05',\n",
    "    'dxy_max',\n",
    "    'dz_max',\n",
    "]\n",
    "\n",
    "top_xaugs = []\n",
    "\n",
    "if('+ 5 XAUGS' in option):\n",
    "    top_xaugs = top_five_xaugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInputInfo(option, top_xaugs = []):\n",
    "    \n",
    "    \n",
    "    \n",
    "    particleInfo = True\n",
    "    xaugs = True\n",
    "    flavor = True\n",
    "\n",
    "    if('Particle List Only'==option):\n",
    "        particleInfo = True\n",
    "        xaugs = False\n",
    "        flavor = False\n",
    "        \n",
    "    elif('Particle List + all XAUGS'==option):\n",
    "        particleInfo = True\n",
    "        xaugs = True\n",
    "        flavor = True\n",
    "        \n",
    "    elif('Particle List + XAUGS no flavor'==option):\n",
    "        particleInfo = True\n",
    "        xaugs = True\n",
    "        flavor = True\n",
    "        \n",
    "    elif('Particle List + 5 XAUGS'==option):\n",
    "        particleInfo = True\n",
    "        xaugs = False\n",
    "        flavor = False\n",
    "        \n",
    "    elif('XAUGS only'==option):\n",
    "        particleInfo = False\n",
    "        xaugs = True\n",
    "        flavor = True\n",
    "    \n",
    "    elif('XAUGS only no flavor'==option):\n",
    "        particleInfo = False\n",
    "        xaugs = True\n",
    "        flavor = False\n",
    "        \n",
    "        \n",
    "    features = get_feat(xaugs=xaugs, flav=flavor, particleInfo=particleInfo)\n",
    "    \n",
    "    features += top_xaugs\n",
    "\n",
    "    nXvar = 0\n",
    "    if(xaugs): nXvar = 29\n",
    "    if(flavor): nXvar += 7    \n",
    "    nXvar += len(top_xaugs)\n",
    "        \n",
    "        \n",
    "    print('option = {0}'.format(option))\n",
    "    print('particleInfo = {0}'.format(particleInfo))\n",
    "    print('xaugs = {0}'.format(xaugs))\n",
    "    print('flavor = {0}'.format(flavor))\n",
    "    print('nXvar = {0}'.format(nXvar))\n",
    "\n",
    "    \n",
    "        \n",
    "    return features, nXvar, particleInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, nXvar, particleInfo = getInputInfo(option, top_xaugs = top_xaugs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalVar = len(features)\n",
    "for i, feat in enumerate(features):\n",
    "    print(i, feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test,  Y_test  = build_XY(features, ['labels'], test_sig,  test_bkg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete loaded npz files\n",
    "del test_sig\n",
    "del test_bkg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printTime(delta, words='Elapsed Time'):\n",
    "    time_string = words + ': ' +'{0:0.1f} h {1:0.1f} min {2:0.2f} sec'.format(delta // 3600, delta % 3600 // 60, delta % 3600 % 60)\n",
    "    print(time_string) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lrp_score(test_inputs, model, nXvar, totalVar, batch=20):\n",
    "    \n",
    "    # model loaded from model = keras.models.load_model(model_name)\n",
    "    # nXvar = number of expert features (xaugs)\n",
    "    # totalVar = total number of features\n",
    "    # batch = number of constituent particles per event\n",
    "    \n",
    "    lrp_toc = time.time()\n",
    "    \n",
    "    # strip model of softmax layer\n",
    "    best_model_wo_softmax = innvestigate.utils.keras.graph.model_wo_softmax(model)\n",
    "     \n",
    "    # build lrp analyzer using Preset A: LRP_alpha1beta0 for conv layers and LRP_epsilon for dense layers\n",
    "    lrp_analyzer = innvestigate.analyzer.relevance_based.relevance_analyzer.LRPSequentialPresetA(best_model_wo_softmax)\n",
    "   \n",
    "    # run lrp analysis in chunks so that kernel does not die\n",
    "    nElem = 10000\n",
    "    batchsize = test_inputs[0].shape[0]\n",
    "    slices = batchsize // nElem\n",
    "    size_from_loop = batchsize - (batchsize % nElem)\n",
    "    \n",
    "    print()\n",
    "    print('Running LRP Analysis')\n",
    "    print('Total Events: {0:0.0f}'.format(batchsize))\n",
    "    print('Split into chunk size: {0:0.0f}'.format(nElem))\n",
    "    print()\n",
    "    \n",
    "    lrp_list = []\n",
    "    \n",
    "\n",
    "    # get lrp scores from all chunks except last chunk\n",
    "    for i in range(slices):\n",
    "\n",
    "        lrp_i = lrp_analyzer.analyze([element[nElem*i:nElem*(i+1)] for element in test_inputs])\n",
    "        lrp_list.append(lrp_i)\n",
    "        del lrp_i\n",
    "\n",
    "    \n",
    "    # get lrp scores from last chunk\n",
    "    lrp_list_last = lrp_analyzer.analyze([element[size_from_loop:] for element in test_inputs])\n",
    "    \n",
    "    # combine chunks into separate arrays for particle list features (lrp_plist) and xaug features (lrp_xaugs)\n",
    "    lrp_plist_list = []\n",
    "    lrp_xaugs_list = []\n",
    "    \n",
    "    lrp_plist_list_last = []\n",
    "    lrp_xaugs_list_last = []\n",
    "\n",
    "\n",
    "    # append lrp scores to lrp_plist or lrp_xaugs\n",
    "    for i in range(totalVar):\n",
    "        for s in range(slices):\n",
    "            if(i < (totalVar-nXvar)):\n",
    "                lrp_plist_list.append(lrp_list[s][i])\n",
    "                    \n",
    "            else:\n",
    "                lrp_xaugs_list.append(lrp_list[s][i])\n",
    "                \n",
    "    # append lrp scores from last chunk         \n",
    "    for i in range(totalVar):\n",
    "        if(i < (totalVar-nXvar)):\n",
    "            lrp_plist_list_last.append(lrp_list_last[i])\n",
    "\n",
    "        else:\n",
    "            lrp_xaugs_list_last.append(lrp_list_last[i])\n",
    "                \n",
    "                \n",
    "    # copy to arrays           \n",
    "    lrp_plist_first = np.array(lrp_plist_list).reshape(totalVar-nXvar, size_from_loop, batch, 1)\n",
    "    lrp_xaugs_first = np.array(lrp_xaugs_list).reshape(nXvar, size_from_loop, 1)\n",
    "    \n",
    "    lrp_plist_last = np.array(lrp_plist_list_last).reshape(totalVar-nXvar,(batchsize % nElem),batch,1)\n",
    "    lrp_xaugs_last = np.array(lrp_xaugs_list_last).reshape(nXvar,(batchsize % nElem),1)\n",
    "                \n",
    "    \n",
    "    # append last chunk to lrp scores arrays\n",
    "    lrp_plist = np.append(lrp_plist_first, lrp_plist_last, axis=1)\n",
    "    lrp_xaugs = np.append(lrp_xaugs_first, lrp_xaugs_last, axis=1)\n",
    "\n",
    "    del lrp_plist_list\n",
    "    del lrp_xaugs_list\n",
    "    del lrp_plist_list_last\n",
    "    del lrp_xaugs_list_last\n",
    "    del lrp_list\n",
    "    \n",
    "    lrp_tic = time.time()\n",
    "    \n",
    "    print()\n",
    "    printTime(lrp_tic - lrp_toc, 'LRP Analysis Time')\n",
    "    \n",
    "    return lrp_plist, lrp_xaugs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalized_lrp_score(lrp_plist, lrp_xaugs):\n",
    "\n",
    "    lrp_plist_norm = np.zeros_like(lrp_plist)\n",
    "    lrp_xaugs_norm = np.zeros_like(lrp_xaugs)\n",
    "    \n",
    "    if(len(lrp_plist > 0)):\n",
    "        for i in range(lrp_plist.shape[1]):\n",
    "\n",
    "            maxval = np.max(abs(lrp_plist[:,i].flatten()))\n",
    "            if(maxval < 1e-6): maxval = 1.\n",
    "            lrp_plist_norm[:,i] = lrp_plist[:,i] / maxval\n",
    "\n",
    "    if(len(lrp_xaugs > 0)):   \n",
    "        for i in range(analysis_a1b0_full_xv_norm.shape[1]):\n",
    "\n",
    "            maxval = np.max(abs(lrp_xaugs[:,i].flatten()))\n",
    "            lrp_xaugs_norm[:,i] = lrp_xaugs[:,i] / maxval\n",
    "    \n",
    "    \n",
    "    return lrp_plist_norm, lrp_xaugs_norm\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_profile_data(x,values,bins):\n",
    "    bin_mean, bin_edges, _ = stats.binned_statistic(x,\n",
    "                                                    values,\n",
    "                                                    statistic = 'mean',\n",
    "                                                    bins = bins,\n",
    "                                                    range = (0,1))\n",
    "    bin_std, _, _ = stats.binned_statistic(x,\n",
    "                                           values,\n",
    "                                           statistic = 'std',\n",
    "                                           bins = bins,\n",
    "                                           range = (0,1))\n",
    "    bin_count, _, _ = stats.binned_statistic(x,\n",
    "                                             x,\n",
    "                                             statistic = 'count',\n",
    "                                             bins = bins,\n",
    "                                             range = (0,1))\n",
    "    bin_width = (bin_edges[1] - bin_edges[0])\n",
    "    bin_centers = bin_edges[1:] - bin_width/2\n",
    "    return bin_mean, bin_std, bin_count, bin_edges, bin_centers, bin_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Draw_Profile(X_test, Y_test, pred, LRP_norm, feat, bins, histomax, relmin, relmax):\n",
    "    ii = features.index(feat)\n",
    "    \n",
    "#     print(ii)\n",
    "#     print(features[ii])\n",
    "#     print(LRP_norm[ii])\n",
    "#     ind_positive = np.argwhere((pred[:,0,1]>confidence_cut)).flatten()\n",
    "#     ind_negative = np.argwhere((pred[:,0,0]>confidence_cut)).flatten()\n",
    "\n",
    "    ind_positive = (Y_test[0][:,1]==1)\n",
    "    ind_negative = (Y_test[0][:,1]==0)\n",
    "\n",
    "    LRP_p = LRP_norm[ii][ind_positive].flatten()\n",
    "    LRP_n = LRP_norm[ii][ind_negative].flatten()\n",
    "    X_p = X_test[ii][ind_positive].flatten()\n",
    "    X_n = X_test[ii][ind_negative].flatten()\n",
    "    \n",
    "    bin_mean_p, bin_std_p, bin_count_p, bin_edges, bin_centers, bin_width = make_profile_data(X_p, LRP_p, bins)\n",
    "    bin_mean_n, bin_std_n, bin_count_n, _, _, _  = make_profile_data(X_n, LRP_n, bins)\n",
    "    \n",
    "    bin_mean_p[bin_count_p < 50] = np.nan\n",
    "    bin_std_p[bin_count_p < 50] = 0\n",
    "    \n",
    "    bin_mean_n[bin_count_n < 50] = np.nan\n",
    "    bin_std_n[bin_count_n < 50] = 0\n",
    "\n",
    "    fig = plt.figure(figsize=(6,7))\n",
    "    gs = gridspec.GridSpec(3, 1) \n",
    "    gs.update(wspace=0.025, hspace=0.1)\n",
    "    \n",
    "    ax0 = plt.subplot(gs[:2,:])\n",
    "    ax0.hist(X_p.flatten(),\n",
    "                bins = bins,\n",
    "                histtype = 'step',\n",
    "#                normed=False,\n",
    "                weights = np.ones(len(X_p.flatten()))/len(X_p.flatten()),\n",
    "                fill = True,\n",
    "                alpha = 0.55,\n",
    "                label = \"Signal\",\n",
    "                log = False,\n",
    "#                density = True,\n",
    "                range = [0,1],\n",
    "                hatch='/',\n",
    "                edgecolor='k'\n",
    "                );\n",
    "    ax0.hist(X_n.flatten(),\n",
    "                bins = bins,\n",
    "                histtype = 'step',\n",
    "#                normed=False,\n",
    "                weights = np.ones(len(X_n.flatten()))/len(X_n.flatten()),\n",
    "                fill = True,\n",
    "                alpha = 0.55,\n",
    "                label = 'Background',\n",
    "                log = False,\n",
    "#                density = True,\n",
    "                range = [0,1],\n",
    "                hatch = '\\\\',\n",
    "                edgecolor='k'\n",
    "                );\n",
    "    l = ax0.legend();\n",
    "#    ax0.grid()\n",
    "    ax0.set_xlim(0,1)\n",
    "    ax0.set_ylim(0,histomax)\n",
    "\n",
    "    ax0.set_ylabel('Fraction')\n",
    "\n",
    "    ax1 = plt.subplot(gs[2:,:])\n",
    "    ax1.xaxis.set_ticks(np.arange(0, 1.2, 0.2))\n",
    "    plt.setp(ax0.get_xticklabels(), visible=False)\n",
    "    ax1.plot(bin_centers,\n",
    "             bin_mean_p,\n",
    "             color = 'C0',\n",
    "             label = \"Signal\")\n",
    "    ax1.plot(bin_centers,\n",
    "             bin_mean_n,\n",
    "             color = 'C1',\n",
    "             label = \"Background\")\n",
    "    ax1.fill_between(bin_centers,\n",
    "                     bin_mean_p - bin_std_p,\n",
    "                     bin_mean_p + bin_std_p,\n",
    "                     color = 'C0',\n",
    "                     alpha = 0.2)\n",
    "    ax1.fill_between(bin_centers,\n",
    "                     bin_mean_n - bin_std_n,\n",
    "                     bin_mean_n + bin_std_n,\n",
    "                     color = 'C1',\n",
    "                     alpha = 0.2)\n",
    "    ax1.grid()\n",
    "    ax1.set_ylim(relmin,relmax)\n",
    "    ax1.set_xlim(0, 1)\n",
    "    ax1.set_ylabel('Relevance')\n",
    "    ax1.set_xlabel('Rescaled ' + feature_names[feat])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get LRP Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrp_plist, lrp_xaugs = get_lrp_score(X_test, best_model, nXvar, totalVar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Normalized LRP Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrp_plist_norm, lrp_xaugs_norm, = get_normalized_lrp_score(lrp_plist, lrp_xaugs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names={'jetPt':r'$p_{T,jet}$',\n",
    "               'jetEta':r'$\\eta(jet)$',\n",
    "               'jetPhi':r'$\\phi(jet)$',\n",
    "               'jetMass':r'$m_{jet}$',\n",
    "               'jetMassSD':r'$m_{jet,sd}$',\n",
    "               'tau1_b05':r'$\\tau_{1}^{(0.5)}$',\n",
    "               'tau2_b05':r'$\\tau_{2}^{(0.5)}$',\n",
    "               'tau3_b05':r'$\\tau_{3}^{(0.5)}$',\n",
    "               'tau1_sd_b05':r'$\\tau_{1,sd}^{(0.5)}$',\n",
    "               'tau2_sd_b05':r'$\\tau_{2,sd}^{(0.5)}$',\n",
    "               'tau3_sd_b05':r'$\\tau_{3,sd}^{(0.5)}$',\n",
    "               'tau1_b10':r'$\\tau_{1}^{(1)}$',\n",
    "               'tau2_b10':r'$\\tau_{2}^{(1)}$',\n",
    "               'tau3_b10':r'$\\tau_{3}^{(1)}$',\n",
    "               'tau1_sd_b10':r'$\\tau_{1,sd}^{(1)}$',\n",
    "               'tau2_sd_b10':r'$\\tau_{2,sd}^{(1)}$',\n",
    "               'tau3_sd_b10':r'$\\tau_{3,sd}^{(1)}$',\n",
    "               'tau1_b15':r'$\\tau_{1}^{(1.5)}$',\n",
    "               'tau2_b15':r'$\\tau_{2}^{(1.5)}$',\n",
    "               'tau3_b15':r'$\\tau_{3}^{(1.5)}$',\n",
    "               'tau1_sd_b15':r'$\\tau_{1,sd}^{(1.5)}$',\n",
    "               'tau2_sd_b15':r'$\\tau_{2,sd}^{(1.5)}$',\n",
    "               'tau3_sd_b15':r'$\\tau_{3,sd}^{(1.5)}$',\n",
    "               'tau1_b20':r'$\\tau_{1}^{(2)}$',\n",
    "               'tau2_b20':r'$\\tau_{2}^{(2)}$',\n",
    "               'tau3_b20':r'$\\tau_{3}^{(2)}$',\n",
    "               'tau1_sd_b20':r'$\\tau_{1,sd}^{(2)}$',\n",
    "               'tau2_sd_b20':r'$\\tau_{2,sd}^{(2)}$',\n",
    "               'tau3_sd_b20':r'$\\tau_{3,sd}^{(2)}$',\n",
    "               'chMult':r'$N_{ch}$',\n",
    "               'neutMult':r'$N_{neut}$',\n",
    "               'phoMult':r'$N_{\\gamma}$',\n",
    "               'eleMult':r'$N_{e}$',\n",
    "               'muMult':r'$N_{\\mu}$',\n",
    "               'jetpull':r'$\\phi_{pull}$',\n",
    "               'beta3':r'$\\beta_{3}$',\n",
    "               'beta3_sd':r'$\\beta_{3}^{g}$',\n",
    "               'tau21':r'$\\tau_{2}^{(1)} / \\tau_{1}^{(1)}$',\n",
    "               'deltaR_subjets':r'$\\Delta_r$',\n",
    "               'z':r'$z$',\n",
    "               'dxy_max':r'$d_{xy,max}$',\n",
    "               'dz_max':r'$d_{z,max}$',\n",
    "               'dxy':'$d_{xy}$',\n",
    "               'dz':'$d_{z}$',\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relmin = -1\n",
    "relmax = 1\n",
    "bins = 50\n",
    "histomax = 0.41\n",
    "feat = 'dxy'\n",
    "\n",
    "\n",
    "Draw_Profile(X_test, Y_test, pred, lrp_plist_norm, feat, bins, histomax, relmin, relmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relmin = -1\n",
    "relmax = 1\n",
    "bins = 50\n",
    "histomax = 0.41\n",
    "feat = 'dz'\n",
    "\n",
    "\n",
    "Draw_Profile(X_test, Y_test, pred, lrp_plist_norm, feat, bins, histomax, relmin, relmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
