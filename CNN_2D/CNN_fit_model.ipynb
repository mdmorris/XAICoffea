{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/schubert/.conda/envs/LRP/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/schubert/.conda/envs/LRP/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/schubert/.conda/envs/LRP/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/schubert/.conda/envs/LRP/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/schubert/.conda/envs/LRP/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/schubert/.conda/envs/LRP/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "import keras.backend\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "import keras.utils\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import sklearn\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_CNN():\n",
    "    input2 = [layers.Input(shape = (len(X_train[i][0]),)) for i in range(1,len(X_train))]\n",
    "    input1 = layers.Input(shape = (grid, grid,1))\n",
    "    x = layers.Conv2D(32, (5, 5), activation = 'relu', padding = 'same')(input1)\n",
    "    x = layers.Conv2D(32, (3, 3), activation = 'relu', padding = 'same')(x)\n",
    "    x = layers.Conv2D(32, (2, 2), activation = 'relu', padding = 'same')(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.MaxPool2D((2, 2))(x)\n",
    "    x1 = layers.Flatten()(x)\n",
    "    if input2 == []:\n",
    "        x = layers.Dense(64, activation='relu', name = 'dense1')(x1)\n",
    "    else:\n",
    "        x = layers.concatenate(inputs = [x1] + input2, axis = -1)\n",
    "        x = layers.Dense(64, activation='relu', name = 'dense2')(x)\n",
    "    x = layers.Dense(128, activation='relu', name = 'dense3')(x)\n",
    "    output = layers.Dense(2, activation='softmax')(x)\n",
    "    model = models.Model(inputs= [input1] + input2,\n",
    "                         outputs = output)\n",
    "    opt = keras.optimizers.Adam(lr = 0.001,\n",
    "                                beta_1 = 0.9,\n",
    "                                beta_2 = 0.999,\n",
    "                                amsgrad = False)\n",
    "    model.compile(loss = 'binary_crossentropy',\n",
    "                optimizer = opt,\n",
    "                metrics = ['binary_crossentropy', 'accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_DNN():\n",
    "    input2 = [layers.Input(shape = (len(X_train[i][0]),)) for i in range(0,len(X_train))]\n",
    "    if len(input2) == 1:\n",
    "        x = layers.Dense(64,activation='relu')(input2[0])\n",
    "    else:\n",
    "        x = layers.concatenate(inputs = input2, axis = -1)\n",
    "        x = layers.Dense(64, activation = 'relu')(x)\n",
    "    x = layers.Dense(128, activation = 'relu')(x)\n",
    "    output = layers.Dense(2, activation = 'softmax')(x)\n",
    "    model = models.Model(inputs = input2, \n",
    "                         outputs = output)\n",
    "    opt=keras.optimizers.Adam(lr = 0.0005,\n",
    "                              beta_1 = 0.9,\n",
    "                              beta_2 = 0.9,\n",
    "                              amsgrad = False)\n",
    "    model.compile(loss = 'binary_crossentropy',\n",
    "                optimizer = opt,\n",
    "                metrics = ['binary_crossentropy', 'accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_XY(features,label,dic):\n",
    "    X = [dic[key] for key in features]\n",
    "    Y = [dic[key] for key in label]\n",
    "    dim = [ele.shape+(1,) for ele in X]\n",
    "    for i in range(0,len(features)):\n",
    "        X[i] = X[i].reshape(dim[i])\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data:\n",
    "Using Train and Test set produced by preprocessing notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = 16\n",
    "data_train = np.load('../data/ShowJet_final_train.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1677864\n"
     ]
    }
   ],
   "source": [
    "n_train = len(data_train['jetPt'])\n",
    "print(n_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jetImages',\n",
       " 'jetPt',\n",
       " 'jetEta',\n",
       " 'jetPhi',\n",
       " 'jetMass',\n",
       " 'jetMassSD',\n",
       " 'tau1_b05',\n",
       " 'tau2_b05',\n",
       " 'tau3_b05',\n",
       " 'tau1_sd_b05',\n",
       " 'tau2_sd_b05',\n",
       " 'tau3_sd_b05',\n",
       " 'tau1_b10',\n",
       " 'tau2_b10',\n",
       " 'tau3_b10',\n",
       " 'tau1_sd_b10',\n",
       " 'tau2_sd_b10',\n",
       " 'tau3_sd_b10',\n",
       " 'tau1_b20',\n",
       " 'tau2_b20',\n",
       " 'tau3_b20',\n",
       " 'tau1_sd_b20',\n",
       " 'tau2_sd_b20',\n",
       " 'tau3_sd_b20',\n",
       " 'chMult',\n",
       " 'neutMult',\n",
       " 'phoMult',\n",
       " 'eleMult',\n",
       " 'muMult',\n",
       " 'jetpull',\n",
       " 'beta3',\n",
       " 'beta3_sd',\n",
       " 'tau21']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "removeFeat = ['tau1_b15', 'tau2_b15', 'tau3_b15',\n",
    "            'tau1_sd_b15', 'tau2_sd_b15', 'tau3_sd_b15',\n",
    "            'labels']\n",
    "feat_all = [key for key in data_train.keys()];\n",
    "for feat in removeFeat:\n",
    "    feat_all.remove(feat)\n",
    "feat_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model with only Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features will be loaded into X\n",
    "features = ['jetImages']\n",
    "\n",
    "# label into Y\n",
    "label = ['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = build_XY(features,label,data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/schubert/.conda/envs/LRP/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "CNN = build_CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 4ms/step\n",
      "[[0.5001186  0.4998814 ]\n",
      " [0.50022477 0.49977526]\n",
      " [0.5001654  0.49983454]\n",
      " [0.5001983  0.49980167]\n",
      " [0.5003264  0.49967366]\n",
      " [0.500041   0.49995905]\n",
      " [0.5004841  0.49951592]\n",
      " [0.5007872  0.49921286]\n",
      " [0.50026095 0.49973908]\n",
      " [0.49996716 0.5000329 ]]\n",
      "[0.6934884190559387, 0.6934884190559387, 0.30000001192092896]\n"
     ]
    }
   ],
   "source": [
    "X_batch = [ele[:10] for ele in X_train]\n",
    "Y_batch = [ele[:10] for ele in Y_train]\n",
    "example_result = CNN.predict(x = X_batch)\n",
    "results = CNN.evaluate(x = X_batch, y = Y_batch )\n",
    "print(example_result)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/schubert/.conda/envs/LRP/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 1342291 samples, validate on 335573 samples\n",
      "Epoch 1/60\n",
      "1342291/1342291 [==============================] - 1867s 1ms/step - loss: 0.5608 - binary_crossentropy: 0.5608 - acc: 0.7102 - val_loss: 0.5421 - val_binary_crossentropy: 0.5421 - val_acc: 0.7237\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.54208, saving model to model/CNN_sub_0.h2\n",
      "Epoch 2/60\n",
      "1342291/1342291 [==============================] - 1726s 1ms/step - loss: 0.5397 - binary_crossentropy: 0.5397 - acc: 0.7263 - val_loss: 0.5347 - val_binary_crossentropy: 0.5347 - val_acc: 0.7289\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.54208 to 0.53468, saving model to model/CNN_sub_0.h2\n",
      "Epoch 3/60\n",
      "1342291/1342291 [==============================] - 2254s 2ms/step - loss: 0.5324 - binary_crossentropy: 0.5324 - acc: 0.7315 - val_loss: 0.5347 - val_binary_crossentropy: 0.5347 - val_acc: 0.7302\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.53468\n",
      "Epoch 4/60\n",
      "1342291/1342291 [==============================] - 1631s 1ms/step - loss: 0.5285 - binary_crossentropy: 0.5285 - acc: 0.7346 - val_loss: 0.5304 - val_binary_crossentropy: 0.5304 - val_acc: 0.7318\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.53468 to 0.53035, saving model to model/CNN_sub_0.h2\n",
      "Epoch 5/60\n",
      "1342291/1342291 [==============================] - 1716s 1ms/step - loss: 0.5254 - binary_crossentropy: 0.5254 - acc: 0.7364 - val_loss: 0.5242 - val_binary_crossentropy: 0.5242 - val_acc: 0.7365\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.53035 to 0.52416, saving model to model/CNN_sub_0.h2\n",
      "Epoch 6/60\n",
      "1342291/1342291 [==============================] - 1753s 1ms/step - loss: 0.5228 - binary_crossentropy: 0.5228 - acc: 0.7384 - val_loss: 0.5245 - val_binary_crossentropy: 0.5245 - val_acc: 0.7368\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.52416\n",
      "Epoch 7/60\n",
      "1342291/1342291 [==============================] - 1803s 1ms/step - loss: 0.5210 - binary_crossentropy: 0.5210 - acc: 0.7397 - val_loss: 0.5232 - val_binary_crossentropy: 0.5232 - val_acc: 0.7374\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.52416 to 0.52322, saving model to model/CNN_sub_0.h2\n",
      "Epoch 8/60\n",
      "1342291/1342291 [==============================] - 1826s 1ms/step - loss: 0.5197 - binary_crossentropy: 0.5197 - acc: 0.7405 - val_loss: 0.5225 - val_binary_crossentropy: 0.5225 - val_acc: 0.7389\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.52322 to 0.52249, saving model to model/CNN_sub_0.h2\n",
      "Epoch 9/60\n",
      "1342291/1342291 [==============================] - 1838s 1ms/step - loss: 0.5186 - binary_crossentropy: 0.5186 - acc: 0.7412 - val_loss: 0.5206 - val_binary_crossentropy: 0.5206 - val_acc: 0.7398\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.52249 to 0.52061, saving model to model/CNN_sub_0.h2\n",
      "Epoch 10/60\n",
      "1342291/1342291 [==============================] - 1848s 1ms/step - loss: 0.5179 - binary_crossentropy: 0.5179 - acc: 0.7416 - val_loss: 0.5265 - val_binary_crossentropy: 0.5265 - val_acc: 0.7361\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.52061\n",
      "Epoch 11/60\n",
      "1342291/1342291 [==============================] - 1850s 1ms/step - loss: 0.5165 - binary_crossentropy: 0.5165 - acc: 0.7428 - val_loss: 0.5220 - val_binary_crossentropy: 0.5220 - val_acc: 0.7388\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.52061\n",
      "Epoch 12/60\n",
      "1342291/1342291 [==============================] - 1859s 1ms/step - loss: 0.5165 - binary_crossentropy: 0.5165 - acc: 0.7429 - val_loss: 0.5204 - val_binary_crossentropy: 0.5204 - val_acc: 0.7391\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.52061 to 0.52044, saving model to model/CNN_sub_0.h2\n",
      "Epoch 13/60\n",
      "1342291/1342291 [==============================] - 1866s 1ms/step - loss: 0.5157 - binary_crossentropy: 0.5157 - acc: 0.7433 - val_loss: 0.5260 - val_binary_crossentropy: 0.5260 - val_acc: 0.7387\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.52044\n",
      "Epoch 14/60\n",
      "1342291/1342291 [==============================] - 1814s 1ms/step - loss: 0.5148 - binary_crossentropy: 0.5148 - acc: 0.7439 - val_loss: 0.5179 - val_binary_crossentropy: 0.5179 - val_acc: 0.7415\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.52044 to 0.51786, saving model to model/CNN_sub_0.h2\n",
      "Epoch 15/60\n",
      "1342291/1342291 [==============================] - 1802s 1ms/step - loss: 0.5155 - binary_crossentropy: 0.5155 - acc: 0.7438 - val_loss: 0.5203 - val_binary_crossentropy: 0.5203 - val_acc: 0.7389\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.51786\n",
      "Epoch 16/60\n",
      "1342291/1342291 [==============================] - 1808s 1ms/step - loss: 0.5137 - binary_crossentropy: 0.5137 - acc: 0.7446 - val_loss: 0.5192 - val_binary_crossentropy: 0.5192 - val_acc: 0.7403\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.51786\n",
      "Epoch 17/60\n",
      "1342291/1342291 [==============================] - 1812s 1ms/step - loss: 0.5134 - binary_crossentropy: 0.5134 - acc: 0.7451 - val_loss: 0.5197 - val_binary_crossentropy: 0.5197 - val_acc: 0.7401\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.51786\n",
      "Epoch 18/60\n",
      "1342291/1342291 [==============================] - 1804s 1ms/step - loss: 0.5142 - binary_crossentropy: 0.5142 - acc: 0.7450 - val_loss: 0.5222 - val_binary_crossentropy: 0.5222 - val_acc: 0.7390\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.51786\n",
      "Epoch 19/60\n",
      "1342291/1342291 [==============================] - 1792s 1ms/step - loss: 0.5126 - binary_crossentropy: 0.5126 - acc: 0.7455 - val_loss: 0.5177 - val_binary_crossentropy: 0.5177 - val_acc: 0.7421\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.51786 to 0.51765, saving model to model/CNN_sub_0.h2\n",
      "Epoch 20/60\n",
      "1342291/1342291 [==============================] - 1811s 1ms/step - loss: 0.5125 - binary_crossentropy: 0.5125 - acc: 0.7458 - val_loss: 0.5238 - val_binary_crossentropy: 0.5238 - val_acc: 0.7397\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.51765\n",
      "Epoch 21/60\n",
      "1342291/1342291 [==============================] - 1815s 1ms/step - loss: 0.5124 - binary_crossentropy: 0.5124 - acc: 0.7457 - val_loss: 0.5194 - val_binary_crossentropy: 0.5194 - val_acc: 0.7419\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.51765\n",
      "Epoch 22/60\n",
      "1342291/1342291 [==============================] - 1812s 1ms/step - loss: 0.5191 - binary_crossentropy: 0.5191 - acc: 0.7454 - val_loss: 0.5503 - val_binary_crossentropy: 0.5503 - val_acc: 0.7408\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.51765\n",
      "Epoch 23/60\n",
      "1342291/1342291 [==============================] - 1809s 1ms/step - loss: 0.5159 - binary_crossentropy: 0.5159 - acc: 0.7457 - val_loss: 0.5236 - val_binary_crossentropy: 0.5236 - val_acc: 0.7416\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.51765\n",
      "Epoch 24/60\n",
      "1342291/1342291 [==============================] - 1813s 1ms/step - loss: 0.5117 - binary_crossentropy: 0.5117 - acc: 0.7466 - val_loss: 0.5177 - val_binary_crossentropy: 0.5177 - val_acc: 0.7436\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.51765\n",
      "Epoch 25/60\n",
      "1342291/1342291 [==============================] - 1813s 1ms/step - loss: 0.5175 - binary_crossentropy: 0.5175 - acc: 0.7461 - val_loss: 0.5398 - val_binary_crossentropy: 0.5398 - val_acc: 0.7368\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.51765\n",
      "Epoch 26/60\n",
      "1342291/1342291 [==============================] - 1815s 1ms/step - loss: 0.5135 - binary_crossentropy: 0.5135 - acc: 0.7459 - val_loss: 0.5165 - val_binary_crossentropy: 0.5165 - val_acc: 0.7429\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.51765 to 0.51646, saving model to model/CNN_sub_0.h2\n",
      "Epoch 27/60\n",
      "1342291/1342291 [==============================] - 1720s 1ms/step - loss: 0.5119 - binary_crossentropy: 0.5119 - acc: 0.7467 - val_loss: 0.5191 - val_binary_crossentropy: 0.5191 - val_acc: 0.7406\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.51646\n",
      "Epoch 28/60\n",
      "1342291/1342291 [==============================] - 1589s 1ms/step - loss: 0.5126 - binary_crossentropy: 0.5126 - acc: 0.7464 - val_loss: 0.5189 - val_binary_crossentropy: 0.5189 - val_acc: 0.7419\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.51646\n",
      "Epoch 29/60\n",
      "1342291/1342291 [==============================] - 1597s 1ms/step - loss: 0.5125 - binary_crossentropy: 0.5125 - acc: 0.7466 - val_loss: 0.5307 - val_binary_crossentropy: 0.5307 - val_acc: 0.7393\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.51646\n",
      "Epoch 30/60\n",
      "1342291/1342291 [==============================] - 1589s 1ms/step - loss: 0.5172 - binary_crossentropy: 0.5172 - acc: 0.7457 - val_loss: 0.5214 - val_binary_crossentropy: 0.5214 - val_acc: 0.7401\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.51646\n",
      "Epoch 31/60\n",
      "1342291/1342291 [==============================] - 1588s 1ms/step - loss: 0.5116 - binary_crossentropy: 0.5116 - acc: 0.7470 - val_loss: 0.5197 - val_binary_crossentropy: 0.5197 - val_acc: 0.7409\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.51646\n",
      "Epoch 32/60\n",
      "1342291/1342291 [==============================] - 1591s 1ms/step - loss: 0.5115 - binary_crossentropy: 0.5115 - acc: 0.7471 - val_loss: 0.5184 - val_binary_crossentropy: 0.5184 - val_acc: 0.7428\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.51646\n",
      "Epoch 33/60\n",
      "1342291/1342291 [==============================] - 1201s 895us/step - loss: 0.5114 - binary_crossentropy: 0.5114 - acc: 0.7470 - val_loss: 0.5219 - val_binary_crossentropy: 0.5219 - val_acc: 0.7414\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.51646\n",
      "Epoch 34/60\n",
      "1342291/1342291 [==============================] - 912s 679us/step - loss: 0.5119 - binary_crossentropy: 0.5119 - acc: 0.7466 - val_loss: 0.5170 - val_binary_crossentropy: 0.5170 - val_acc: 0.7432\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.51646\n",
      "Epoch 35/60\n",
      "1342291/1342291 [==============================] - 957s 713us/step - loss: 0.5173 - binary_crossentropy: 0.5173 - acc: 0.7465 - val_loss: 0.5290 - val_binary_crossentropy: 0.5290 - val_acc: 0.7389\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.51646\n",
      "Epoch 36/60\n",
      "1342291/1342291 [==============================] - 951s 709us/step - loss: 0.5124 - binary_crossentropy: 0.5124 - acc: 0.7471 - val_loss: 0.5193 - val_binary_crossentropy: 0.5193 - val_acc: 0.7425\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.51646\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"model/CNN_sub_0.h2\"\n",
    "if not os.path.exists(\"model\"):\n",
    "    os.mkdir(\"model\")\n",
    "\n",
    "model_checkpoint = keras.callbacks.ModelCheckpoint(checkpoint_path, monitor = 'val_loss', \n",
    "                                                   verbose = 1, save_best_only = True, \n",
    "                                                   save_weights_only = False, mode = 'auto', \n",
    "                                                   period = 1)    \n",
    "EPOCHS = 60\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 10)\n",
    "history = CNN.fit(\n",
    "    X_train, Y_train,\n",
    "    epochs = EPOCHS, \n",
    "    validation_split = 0.2,\n",
    "    verbose = 1,\n",
    "    callbacks = [early_stop, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('history/CNN_sub_0.h2.history', 'wb') as file_pi:\n",
    "    pickle.dump(history.history, file_pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model with all Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Features for Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show all possible features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features will be loaded into X\n",
    "features = feat_all\n",
    "\n",
    "# label into Y\n",
    "label = ['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = build_XY(features,label,data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN = build_CNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test model's prediction $before$ training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 8ms/step\n",
      "[[0.45223165 0.54776835]\n",
      " [0.46858796 0.53141207]\n",
      " [0.47678593 0.52321404]\n",
      " [0.48226115 0.5177388 ]\n",
      " [0.47568065 0.52431935]\n",
      " [0.46966124 0.53033876]\n",
      " [0.4805692  0.51943076]\n",
      " [0.46108103 0.5389189 ]\n",
      " [0.4826258  0.51737416]\n",
      " [0.47243115 0.5275688 ]]\n",
      "[0.6786078810691833, 0.6786078810691833, 0.6000000238418579]\n"
     ]
    }
   ],
   "source": [
    "X_batch = [ele[:10] for ele in X_train]\n",
    "Y_batch = [ele[:10] for ele in Y_train]\n",
    "example_result = CNN.predict(x = X_batch)\n",
    "results = CNN.evaluate(x = X_batch, y = Y_batch )\n",
    "print(example_result)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now train! (warning: if building CNN, computer tends to get loud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1342291 samples, validate on 335573 samples\n",
      "Epoch 1/60\n",
      "1342291/1342291 [==============================] - 1580s 1ms/step - loss: 0.3542 - binary_crossentropy: 0.3542 - acc: 0.8446 - val_loss: 0.3314 - val_binary_crossentropy: 0.3314 - val_acc: 0.8557\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.33144, saving model to model/CNN_all.h8\n",
      "Epoch 2/60\n",
      "1342291/1342291 [==============================] - 1778s 1ms/step - loss: 0.3320 - binary_crossentropy: 0.3320 - acc: 0.8557 - val_loss: 0.3233 - val_binary_crossentropy: 0.3233 - val_acc: 0.8604\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.33144 to 0.32329, saving model to model/CNN_all.h8\n",
      "Epoch 3/60\n",
      "1342291/1342291 [==============================] - 1719s 1ms/step - loss: 0.3265 - binary_crossentropy: 0.3265 - acc: 0.8583 - val_loss: 0.3290 - val_binary_crossentropy: 0.3290 - val_acc: 0.8565\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.32329\n",
      "Epoch 4/60\n",
      "1342291/1342291 [==============================] - 1842s 1ms/step - loss: 0.3231 - binary_crossentropy: 0.3231 - acc: 0.8602 - val_loss: 0.3221 - val_binary_crossentropy: 0.3221 - val_acc: 0.8605\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.32329 to 0.32209, saving model to model/CNN_all.h8\n",
      "Epoch 5/60\n",
      "1342291/1342291 [==============================] - 1595s 1ms/step - loss: 0.3210 - binary_crossentropy: 0.3210 - acc: 0.8611 - val_loss: 0.3150 - val_binary_crossentropy: 0.3150 - val_acc: 0.8637\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.32209 to 0.31501, saving model to model/CNN_all.h8\n",
      "Epoch 6/60\n",
      "1342291/1342291 [==============================] - 1418s 1ms/step - loss: 0.3191 - binary_crossentropy: 0.3191 - acc: 0.8620 - val_loss: 0.3204 - val_binary_crossentropy: 0.3204 - val_acc: 0.8621\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.31501\n",
      "Epoch 7/60\n",
      "1342291/1342291 [==============================] - 1705s 1ms/step - loss: 0.3179 - binary_crossentropy: 0.3179 - acc: 0.8626 - val_loss: 0.3166 - val_binary_crossentropy: 0.3166 - val_acc: 0.8628\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.31501\n",
      "Epoch 8/60\n",
      "1342291/1342291 [==============================] - 1506s 1ms/step - loss: 0.3169 - binary_crossentropy: 0.3169 - acc: 0.8629 - val_loss: 0.3144 - val_binary_crossentropy: 0.3144 - val_acc: 0.8643\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.31501 to 0.31441, saving model to model/CNN_all.h8\n",
      "Epoch 9/60\n",
      "1342291/1342291 [==============================] - 1575s 1ms/step - loss: 0.3158 - binary_crossentropy: 0.3158 - acc: 0.8634 - val_loss: 0.3195 - val_binary_crossentropy: 0.3195 - val_acc: 0.8611\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.31441\n",
      "Epoch 10/60\n",
      "1342291/1342291 [==============================] - 1553s 1ms/step - loss: 0.3152 - binary_crossentropy: 0.3152 - acc: 0.8638 - val_loss: 0.3143 - val_binary_crossentropy: 0.3143 - val_acc: 0.8640\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.31441 to 0.31427, saving model to model/CNN_all.h8\n",
      "Epoch 11/60\n",
      "1342291/1342291 [==============================] - 2027s 2ms/step - loss: 0.3145 - binary_crossentropy: 0.3145 - acc: 0.8641 - val_loss: 0.3132 - val_binary_crossentropy: 0.3132 - val_acc: 0.8646\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.31427 to 0.31321, saving model to model/CNN_all.h8\n",
      "Epoch 12/60\n",
      "1342291/1342291 [==============================] - 1903s 1ms/step - loss: 0.3139 - binary_crossentropy: 0.3139 - acc: 0.8644 - val_loss: 0.3139 - val_binary_crossentropy: 0.3139 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.31321\n",
      "Epoch 13/60\n",
      "1342291/1342291 [==============================] - 1687s 1ms/step - loss: 0.3136 - binary_crossentropy: 0.3136 - acc: 0.8646 - val_loss: 0.3119 - val_binary_crossentropy: 0.3119 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.31321 to 0.31189, saving model to model/CNN_all.h8\n",
      "Epoch 14/60\n",
      "1342291/1342291 [==============================] - 1663s 1ms/step - loss: 0.3132 - binary_crossentropy: 0.3132 - acc: 0.8650 - val_loss: 0.3126 - val_binary_crossentropy: 0.3126 - val_acc: 0.8648\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.31189\n",
      "Epoch 15/60\n",
      "1342291/1342291 [==============================] - 1760s 1ms/step - loss: 0.3127 - binary_crossentropy: 0.3127 - acc: 0.8650 - val_loss: 0.3110 - val_binary_crossentropy: 0.3110 - val_acc: 0.8659\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.31189 to 0.31102, saving model to model/CNN_all.h8\n",
      "Epoch 16/60\n",
      "1342291/1342291 [==============================] - 1570s 1ms/step - loss: 0.3123 - binary_crossentropy: 0.3123 - acc: 0.8653 - val_loss: 0.3091 - val_binary_crossentropy: 0.3091 - val_acc: 0.8666\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.31102 to 0.30914, saving model to model/CNN_all.h8\n",
      "Epoch 17/60\n",
      "1342291/1342291 [==============================] - 1782s 1ms/step - loss: 0.3121 - binary_crossentropy: 0.3121 - acc: 0.8655 - val_loss: 0.3095 - val_binary_crossentropy: 0.3095 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.30914\n",
      "Epoch 18/60\n",
      "1342291/1342291 [==============================] - 65839s 49ms/step - loss: 0.3117 - binary_crossentropy: 0.3117 - acc: 0.8655 - val_loss: 0.3124 - val_binary_crossentropy: 0.3124 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.30914\n",
      "Epoch 19/60\n",
      "1342291/1342291 [==============================] - 1713s 1ms/step - loss: 0.3114 - binary_crossentropy: 0.3114 - acc: 0.8658 - val_loss: 0.3160 - val_binary_crossentropy: 0.3160 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.30914\n",
      "Epoch 20/60\n",
      "1342291/1342291 [==============================] - 1756s 1ms/step - loss: 0.3111 - binary_crossentropy: 0.3111 - acc: 0.8660 - val_loss: 0.3113 - val_binary_crossentropy: 0.3113 - val_acc: 0.8650\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.30914\n",
      "Epoch 21/60\n",
      "1342291/1342291 [==============================] - 1702s 1ms/step - loss: 0.3107 - binary_crossentropy: 0.3107 - acc: 0.8661 - val_loss: 0.3137 - val_binary_crossentropy: 0.3137 - val_acc: 0.8646\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.30914\n",
      "Epoch 22/60\n",
      "1342291/1342291 [==============================] - 1623s 1ms/step - loss: 0.3106 - binary_crossentropy: 0.3106 - acc: 0.8661 - val_loss: 0.3080 - val_binary_crossentropy: 0.3080 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.30914 to 0.30797, saving model to model/CNN_all.h8\n",
      "Epoch 23/60\n",
      "1342291/1342291 [==============================] - 1639s 1ms/step - loss: 0.3102 - binary_crossentropy: 0.3102 - acc: 0.8662 - val_loss: 0.3076 - val_binary_crossentropy: 0.3076 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.30797 to 0.30763, saving model to model/CNN_all.h8\n",
      "Epoch 24/60\n",
      "1342291/1342291 [==============================] - 1674s 1ms/step - loss: 0.3102 - binary_crossentropy: 0.3102 - acc: 0.8665 - val_loss: 0.3158 - val_binary_crossentropy: 0.3158 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.30763\n",
      "Epoch 25/60\n",
      "1342291/1342291 [==============================] - 1699s 1ms/step - loss: 0.3097 - binary_crossentropy: 0.3097 - acc: 0.8664 - val_loss: 0.3113 - val_binary_crossentropy: 0.3113 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.30763\n",
      "Epoch 26/60\n",
      "1342291/1342291 [==============================] - 1729s 1ms/step - loss: 0.3097 - binary_crossentropy: 0.3097 - acc: 0.8664 - val_loss: 0.3080 - val_binary_crossentropy: 0.3080 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.30763\n",
      "Epoch 27/60\n",
      "1342291/1342291 [==============================] - 1744s 1ms/step - loss: 0.3094 - binary_crossentropy: 0.3094 - acc: 0.8669 - val_loss: 0.3130 - val_binary_crossentropy: 0.3130 - val_acc: 0.8657\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.30763\n",
      "Epoch 28/60\n",
      "1342291/1342291 [==============================] - 1757s 1ms/step - loss: 0.3092 - binary_crossentropy: 0.3092 - acc: 0.8667 - val_loss: 0.3159 - val_binary_crossentropy: 0.3159 - val_acc: 0.8670\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.30763\n",
      "Epoch 29/60\n",
      "1342291/1342291 [==============================] - 1146s 854us/step - loss: 0.3091 - binary_crossentropy: 0.3091 - acc: 0.8668 - val_loss: 0.3089 - val_binary_crossentropy: 0.3089 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.30763\n",
      "Epoch 30/60\n",
      "1342291/1342291 [==============================] - 800s 596us/step - loss: 0.3089 - binary_crossentropy: 0.3089 - acc: 0.8669 - val_loss: 0.3082 - val_binary_crossentropy: 0.3082 - val_acc: 0.8668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00030: val_loss did not improve from 0.30763\n",
      "Epoch 31/60\n",
      "1342291/1342291 [==============================] - 799s 595us/step - loss: 0.3089 - binary_crossentropy: 0.3089 - acc: 0.8670 - val_loss: 0.3072 - val_binary_crossentropy: 0.3072 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.30763 to 0.30722, saving model to model/CNN_all.h8\n",
      "Epoch 32/60\n",
      "1342291/1342291 [==============================] - 798s 595us/step - loss: 0.3085 - binary_crossentropy: 0.3085 - acc: 0.8671 - val_loss: 0.3076 - val_binary_crossentropy: 0.3076 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.30722\n",
      "Epoch 33/60\n",
      "1342291/1342291 [==============================] - 799s 595us/step - loss: 0.3084 - binary_crossentropy: 0.3084 - acc: 0.8671 - val_loss: 0.3081 - val_binary_crossentropy: 0.3081 - val_acc: 0.8679\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.30722\n",
      "Epoch 34/60\n",
      "1342291/1342291 [==============================] - 799s 595us/step - loss: 0.3083 - binary_crossentropy: 0.3083 - acc: 0.8673 - val_loss: 0.3077 - val_binary_crossentropy: 0.3077 - val_acc: 0.8676\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.30722\n",
      "Epoch 35/60\n",
      "1342291/1342291 [==============================] - 798s 594us/step - loss: 0.3081 - binary_crossentropy: 0.3081 - acc: 0.8672 - val_loss: 0.3069 - val_binary_crossentropy: 0.3069 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.30722 to 0.30687, saving model to model/CNN_all.h8\n",
      "Epoch 36/60\n",
      "1342291/1342291 [==============================] - 800s 596us/step - loss: 0.3081 - binary_crossentropy: 0.3081 - acc: 0.8672 - val_loss: 0.3099 - val_binary_crossentropy: 0.3099 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.30687\n",
      "Epoch 37/60\n",
      "1342291/1342291 [==============================] - 798s 595us/step - loss: 0.3080 - binary_crossentropy: 0.3080 - acc: 0.8674 - val_loss: 0.3089 - val_binary_crossentropy: 0.3089 - val_acc: 0.8672\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.30687\n",
      "Epoch 38/60\n",
      "1342291/1342291 [==============================] - 799s 596us/step - loss: 0.3077 - binary_crossentropy: 0.3077 - acc: 0.8676 - val_loss: 0.3083 - val_binary_crossentropy: 0.3083 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.30687\n",
      "Epoch 39/60\n",
      "1342291/1342291 [==============================] - 799s 595us/step - loss: 0.3078 - binary_crossentropy: 0.3078 - acc: 0.8676 - val_loss: 0.3114 - val_binary_crossentropy: 0.3114 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.30687\n",
      "Epoch 40/60\n",
      "1342291/1342291 [==============================] - 1240s 924us/step - loss: 0.3076 - binary_crossentropy: 0.3076 - acc: 0.8676 - val_loss: 0.3074 - val_binary_crossentropy: 0.3074 - val_acc: 0.8681\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.30687\n",
      "Epoch 41/60\n",
      "1342291/1342291 [==============================] - 1603s 1ms/step - loss: 0.3074 - binary_crossentropy: 0.3074 - acc: 0.8677 - val_loss: 0.3094 - val_binary_crossentropy: 0.3094 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.30687\n",
      "Epoch 42/60\n",
      "1342291/1342291 [==============================] - 1690s 1ms/step - loss: 0.3073 - binary_crossentropy: 0.3073 - acc: 0.8678 - val_loss: 0.3069 - val_binary_crossentropy: 0.3069 - val_acc: 0.8678\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.30687\n",
      "Epoch 43/60\n",
      "1342291/1342291 [==============================] - 1720s 1ms/step - loss: 0.3073 - binary_crossentropy: 0.3073 - acc: 0.8677 - val_loss: 0.3101 - val_binary_crossentropy: 0.3101 - val_acc: 0.8672\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.30687\n",
      "Epoch 44/60\n",
      "1342291/1342291 [==============================] - 1731s 1ms/step - loss: 0.3072 - binary_crossentropy: 0.3072 - acc: 0.8675 - val_loss: 0.3070 - val_binary_crossentropy: 0.3070 - val_acc: 0.8675\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.30687\n",
      "Epoch 45/60\n",
      "1342291/1342291 [==============================] - 1781s 1ms/step - loss: 0.3072 - binary_crossentropy: 0.3072 - acc: 0.8678 - val_loss: 0.3094 - val_binary_crossentropy: 0.3094 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.30687\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"model/CNN_all.h8\"\n",
    "if not os.path.exists(\"model\"):\n",
    "    os.mkdir(\"model\")\n",
    "\n",
    "model_checkpoint = keras.callbacks.ModelCheckpoint(checkpoint_path, monitor = 'val_loss', \n",
    "                                                   verbose = 1, save_best_only = True, \n",
    "                                                   save_weights_only = False, mode = 'auto', \n",
    "                                                   period = 1)    \n",
    "EPOCHS = 60\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 10)\n",
    "history = CNN.fit(\n",
    "    X_train, Y_train,\n",
    "    epochs = EPOCHS,\n",
    "    validation_split = 0.2,\n",
    "    verbose = 1,\n",
    "    callbacks = [early_stop, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('history/CNN_all.h8.history', 'wb') as file_pi:\n",
    "    pickle.dump(history.history, file_pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Features for Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show all possible features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jetImages',\n",
       " 'jetPt',\n",
       " 'jetEta',\n",
       " 'jetPhi',\n",
       " 'jetMass',\n",
       " 'jetMassSD',\n",
       " 'tau1_b05',\n",
       " 'tau2_b05',\n",
       " 'tau3_b05',\n",
       " 'tau1_sd_b05',\n",
       " 'tau2_sd_b05',\n",
       " 'tau3_sd_b05',\n",
       " 'tau1_b10',\n",
       " 'tau2_b10',\n",
       " 'tau3_b10',\n",
       " 'tau1_sd_b10',\n",
       " 'tau2_sd_b10',\n",
       " 'tau3_sd_b10',\n",
       " 'tau1_b20',\n",
       " 'tau2_b20',\n",
       " 'tau3_b20',\n",
       " 'tau1_sd_b20',\n",
       " 'tau2_sd_b20',\n",
       " 'tau3_sd_b20',\n",
       " 'chMult',\n",
       " 'neutMult',\n",
       " 'phoMult',\n",
       " 'eleMult',\n",
       " 'muMult',\n",
       " 'jetpull',\n",
       " 'beta3',\n",
       " 'beta3_sd',\n",
       " 'tau21']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_those = [ 'jetImages',\n",
    " 'chMult',\n",
    " 'neutMult',\n",
    " 'phoMult',\n",
    " 'eleMult',\n",
    " 'muMult']\n",
    "# features will be loaded into X\n",
    "features = feat_all[:]\n",
    "for feat in drop_those:\n",
    "    features.remove(feat)\n",
    "# label into Y\n",
    "label = ['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jetPt',\n",
       " 'jetEta',\n",
       " 'jetPhi',\n",
       " 'jetMass',\n",
       " 'jetMassSD',\n",
       " 'tau1_b05',\n",
       " 'tau2_b05',\n",
       " 'tau3_b05',\n",
       " 'tau1_sd_b05',\n",
       " 'tau2_sd_b05',\n",
       " 'tau3_sd_b05',\n",
       " 'tau1_b10',\n",
       " 'tau2_b10',\n",
       " 'tau3_b10',\n",
       " 'tau1_sd_b10',\n",
       " 'tau2_sd_b10',\n",
       " 'tau3_sd_b10',\n",
       " 'tau1_b20',\n",
       " 'tau2_b20',\n",
       " 'tau3_b20',\n",
       " 'tau1_sd_b20',\n",
       " 'tau2_sd_b20',\n",
       " 'tau3_sd_b20',\n",
       " 'jetpull',\n",
       " 'beta3',\n",
       " 'beta3_sd',\n",
       " 'tau21']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = build_XY(features,label,data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN = build_DNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test model's prediction $before$ training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 10ms/step\n",
      "[[0.5270552  0.4729448 ]\n",
      " [0.5053764  0.4946237 ]\n",
      " [0.5052645  0.49473548]\n",
      " [0.51708007 0.48291987]\n",
      " [0.48523638 0.51476365]\n",
      " [0.54981667 0.45018327]\n",
      " [0.5066523  0.4933477 ]\n",
      " [0.5062908  0.49370918]\n",
      " [0.51445496 0.48554504]\n",
      " [0.5148447  0.48515528]]\n",
      "[0.6866416931152344, 0.6866416931152344, 0.5]\n"
     ]
    }
   ],
   "source": [
    "X_batch = [ele[:10] for ele in X_train]\n",
    "Y_batch = [ele[:10] for ele in Y_train]\n",
    "example_result = CNN.predict(x = X_batch)\n",
    "results = CNN.evaluate(x = X_batch, y = Y_batch )\n",
    "print(example_result)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now train! (warning: if building CNN, computer tends to get loud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1342291 samples, validate on 335573 samples\n",
      "Epoch 1/60\n",
      "1342291/1342291 [==============================] - 78s 58us/step - loss: 0.3736 - binary_crossentropy: 0.3736 - acc: 0.8358 - val_loss: 0.3517 - val_binary_crossentropy: 0.3517 - val_acc: 0.8485\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.35172, saving model to model/DNN_noflavour.h1\n",
      "Epoch 2/60\n",
      "1342291/1342291 [==============================] - 81s 60us/step - loss: 0.3526 - binary_crossentropy: 0.3526 - acc: 0.8483 - val_loss: 0.3554 - val_binary_crossentropy: 0.3554 - val_acc: 0.8486\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.35172\n",
      "Epoch 3/60\n",
      "1342291/1342291 [==============================] - 83s 62us/step - loss: 0.3563 - binary_crossentropy: 0.3563 - acc: 0.8490 - val_loss: 0.3508 - val_binary_crossentropy: 0.3508 - val_acc: 0.8504\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.35172 to 0.35081, saving model to model/DNN_noflavour.h1\n",
      "Epoch 4/60\n",
      "1342291/1342291 [==============================] - 83s 62us/step - loss: 0.3575 - binary_crossentropy: 0.3575 - acc: 0.8494 - val_loss: 0.3629 - val_binary_crossentropy: 0.3629 - val_acc: 0.8460\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.35081\n",
      "Epoch 5/60\n",
      "1342291/1342291 [==============================] - 84s 63us/step - loss: 0.3575 - binary_crossentropy: 0.3575 - acc: 0.8495 - val_loss: 0.3520 - val_binary_crossentropy: 0.3520 - val_acc: 0.8514\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.35081\n",
      "Epoch 6/60\n",
      "1342291/1342291 [==============================] - 83s 62us/step - loss: 0.3557 - binary_crossentropy: 0.3557 - acc: 0.8496 - val_loss: 0.3482 - val_binary_crossentropy: 0.3482 - val_acc: 0.8532\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.35081 to 0.34816, saving model to model/DNN_noflavour.h1\n",
      "Epoch 7/60\n",
      "1342291/1342291 [==============================] - 84s 62us/step - loss: 0.3569 - binary_crossentropy: 0.3569 - acc: 0.8499 - val_loss: 0.3552 - val_binary_crossentropy: 0.3552 - val_acc: 0.8520\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.34816\n",
      "Epoch 8/60\n",
      "1342291/1342291 [==============================] - 85s 63us/step - loss: 0.3585 - binary_crossentropy: 0.3585 - acc: 0.8500 - val_loss: 0.3620 - val_binary_crossentropy: 0.3620 - val_acc: 0.8494\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.34816\n",
      "Epoch 9/60\n",
      "1342291/1342291 [==============================] - 84s 63us/step - loss: 0.3609 - binary_crossentropy: 0.3609 - acc: 0.8494 - val_loss: 0.3625 - val_binary_crossentropy: 0.3625 - val_acc: 0.8489\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.34816\n",
      "Epoch 10/60\n",
      "1342291/1342291 [==============================] - 86s 64us/step - loss: 0.3618 - binary_crossentropy: 0.3618 - acc: 0.8496 - val_loss: 0.3577 - val_binary_crossentropy: 0.3577 - val_acc: 0.8488\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.34816\n",
      "Epoch 11/60\n",
      "1342291/1342291 [==============================] - 86s 64us/step - loss: 0.3618 - binary_crossentropy: 0.3618 - acc: 0.8497 - val_loss: 0.3634 - val_binary_crossentropy: 0.3634 - val_acc: 0.8476\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.34816\n",
      "Epoch 12/60\n",
      "1342291/1342291 [==============================] - 87s 65us/step - loss: 0.3639 - binary_crossentropy: 0.3639 - acc: 0.8494 - val_loss: 0.3695 - val_binary_crossentropy: 0.3695 - val_acc: 0.8483\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.34816\n",
      "Epoch 13/60\n",
      "1342291/1342291 [==============================] - 86s 64us/step - loss: 0.3651 - binary_crossentropy: 0.3651 - acc: 0.8495 - val_loss: 0.3585 - val_binary_crossentropy: 0.3585 - val_acc: 0.8520\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.34816\n",
      "Epoch 14/60\n",
      "1342291/1342291 [==============================] - 86s 64us/step - loss: 0.3644 - binary_crossentropy: 0.3644 - acc: 0.8495 - val_loss: 0.3662 - val_binary_crossentropy: 0.3662 - val_acc: 0.8473\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.34816\n",
      "Epoch 15/60\n",
      "1342291/1342291 [==============================] - 86s 64us/step - loss: 0.3670 - binary_crossentropy: 0.3670 - acc: 0.8495 - val_loss: 0.3719 - val_binary_crossentropy: 0.3719 - val_acc: 0.8468\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.34816\n",
      "Epoch 16/60\n",
      "1342291/1342291 [==============================] - 86s 64us/step - loss: 0.3670 - binary_crossentropy: 0.3670 - acc: 0.8497 - val_loss: 0.3631 - val_binary_crossentropy: 0.3631 - val_acc: 0.8516\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.34816\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"model/DNN_noflavour.h1\"\n",
    "if not os.path.exists(\"model\"):\n",
    "    os.mkdir(\"model\")\n",
    "\n",
    "model_checkpoint = keras.callbacks.ModelCheckpoint(checkpoint_path, monitor = 'val_loss', \n",
    "                                                   verbose = 1, save_best_only = True, \n",
    "                                                   save_weights_only = False, mode = 'auto', \n",
    "                                                   period = 1)    \n",
    "EPOCHS = 60\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 10)\n",
    "history = CNN.fit(\n",
    "    X_train, Y_train,\n",
    "    epochs = EPOCHS,\n",
    "    validation_split = 0.2,\n",
    "    verbose = 1,\n",
    "    callbacks = [early_stop, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('history/DNN_noflavour.h1.history', 'wb') as file_pi:\n",
    "    pickle.dump(history.history, file_pi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
