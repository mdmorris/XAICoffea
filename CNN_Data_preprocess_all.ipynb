{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transparency of Histograms\n",
    "transp = 0.5\n",
    "\n",
    "# If true will plot Zbb sample for signal\n",
    "isZbb = False\n",
    "\n",
    "# apply mass cut and save to separate files\n",
    "applyMassCut = True\n",
    "\n",
    "# create npz files with only images and labels\n",
    "imagesOnly = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib._GeneratorContextManager at 0x7ff4d0b71240>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set default options for paper\n",
    "params = {'legend.fontsize': 'x-large',\n",
    "         'axes.labelsize': 'x-large',\n",
    "         'axes.titlesize':'x-large',\n",
    "         'xtick.labelsize':'x-large',\n",
    "         'ytick.labelsize':'x-large',\n",
    "         'figure.facecolor':'white'}\n",
    "plt.rcParams.update(params)\n",
    "plt.style.context('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "starttime = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = {'jetconstPt_log': r'$log(p_T)$',\n",
    "                'jetconstEta_abs': r'$|\\eta|$',\n",
    "                'jetconstE_log': r'$log(E)$',\n",
    "                'jetconstPt_Jetlog': r'$log(p_T / p_{T}_{jet}$',\n",
    "                'jetMass': r'$m_{jet}$',\n",
    "                'jetMassSD': r'$m_{jet, sd}$',\n",
    "                'deltaR_subjets': r'$\\Delta R_{subjets}$',\n",
    "                'jetPt': r'$p_{T}_{jet}$',\n",
    "                'z': r'$p_{T}_{subjet0} / \\Sigma  p_{T}_{subjets}$',\n",
    "                'tau1_b05': r'$\\tau_{1}^{(0.5)}$',\n",
    "                'tau2_b05': r'$\\tau_{2}^{(0.5)}$',\n",
    "                'tau3_b05': r'$\\tau_{3}^{(0.5)}$',\n",
    "                'tau1_sd_b05': r'$\\tau_{1,sd}^{(0.5)}$',\n",
    "                'tau2_sd_b05': r'$\\tau_{2,sd}^{(0.5)}$',\n",
    "                'tau3_sd_b05': r'$\\tau_{3,sd}^{(0.5)}$',\n",
    "                'tau1_b10': r'$\\tau_{1}^{(1)}$',\n",
    "                'tau2_b10': r'$\\tau_{2}^{(1)}$',\n",
    "                'tau3_b10': r'$\\tau_{3}^{(1)}$',\n",
    "                'tau1_sd_b10': r'$\\tau_{1,sd}^{(1)}$',\n",
    "                'tau2_sd_b10': r'$\\tau_{2,sd}^{(1)}$',\n",
    "                'tau3_sd_b10': r'$\\tau_{3,sd}^{(1)}$',\n",
    "                'tau1_b15': r'$\\tau_{1}^{(1.5)}$',\n",
    "                'tau2_b15': r'$\\tau_{2}^{(1.5)}$',\n",
    "                'tau3_b15': r'$\\tau_{3}^{(1.5)}$',\n",
    "                'tau1_sd_b15': r'$\\tau_{1,sd}^{(1.5)}$',\n",
    "                'tau2_sd_b15': r'$\\tau_{2,sd}^{(1.5)}$',\n",
    "                'tau3_sd_b15': r'$\\tau_{3,sd}^{(1.5)}$',\n",
    "                'tau1_b20': r'$\\tau_{1}^{(2)}$',\n",
    "                'tau2_b20': r'$\\tau_{2}^{(2)}$',\n",
    "                'tau3_b20': r'$\\tau_{3}^{(2)}$',\n",
    "                'tau1_sd_b20': r'$\\tau_{1,sd}^{(2)}$',\n",
    "                'tau2_sd_b20': r'$\\tau_{2,sd}^{(2)}$',\n",
    "                'tau3_sd_b20': r'$\\tau_{3,sd}^{(2)}$',\n",
    "                'charge': r'$q$',\n",
    "                'isEle': r'$isEle$',\n",
    "                'isPho': r'$isPho$',\n",
    "                'isMuon': r'$isMuon$',\n",
    "                'isCh': r'$isCh$',\n",
    "                'isNh': r'$isNh$',\n",
    "                'delta_eta': r'$\\Delta \\eta$',\n",
    "                'delta_phi': r'$\\Delta \\phi$',\n",
    "                'deltaR_jet': r'$\\Delta R_{jet}$',\n",
    "                'deltaR_subjet0': r'$\\Delta R_{subjet0}$',\n",
    "                'deltaR_subjet1': r'$\\Delta R_{subjet1}$',\n",
    "                'jetpull': r'$\\Phi_{pull}$',\n",
    "                'dxy': r'$d_{xy}$',\n",
    "                'dz': r'$d_{z}$',\n",
    "                'jetEta': r'$\\eta_{jet}$',\n",
    "                'jetPhi': r'$\\phi_{jet}$',\n",
    "                'chMult': r'$N_{CH}$',\n",
    "                'neutMult': r'$N_{NH}$',\n",
    "                'phoMult': r'$N_{\\gamma}$',\n",
    "                'eleMult': r'$N_{e}$',\n",
    "                'muMult': r'$N_{\\mu}$',\n",
    "                'beta3': r'$\\beta_{3}$',\n",
    "                'beta3_sd': r'$\\beta_{3, sd}$',\n",
    "                'tau21': r'$\\tau_{2}^{1} / \\tau_{1}^{1}$',\n",
    "                'dxy_max': r'$d_{xy\\ max}$',\n",
    "                'dz_max': r'$d_{z \\max}$',}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fromShowJetsFile = []\n",
    "fromConstituentsFile = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(imagesOnly):\n",
    "    fromShowJetsFile = ['jetImages', 'jetMassSD', 'labels']\n",
    "\n",
    "else:\n",
    "\n",
    "    fromShowJetsFile = [\n",
    "#         'jetImages',\n",
    "        'jetPt',\n",
    "        'jetEta',\n",
    "        'jetPhi',\n",
    "        'jetMass',\n",
    "        'jetMassSD',\n",
    "        'deltaR_subjets',\n",
    "        'z',\n",
    "        'tau1_b05',\n",
    "        'tau2_b05',\n",
    "        'tau3_b05',\n",
    "        'tau1_sd_b05',\n",
    "        'tau2_sd_b05',\n",
    "        'tau3_sd_b05',\n",
    "        'tau1_b10',\n",
    "        'tau2_b10',\n",
    "        'tau3_b10',\n",
    "        'tau1_sd_b10',\n",
    "        'tau2_sd_b10',\n",
    "        'tau3_sd_b10',\n",
    "        'tau1_b15',\n",
    "        'tau2_b15',\n",
    "        'tau3_b15',\n",
    "        'tau1_sd_b15',\n",
    "        'tau2_sd_b15',\n",
    "        'tau3_sd_b15',\n",
    "        'tau1_b20',\n",
    "        'tau2_b20',\n",
    "        'tau3_b20',\n",
    "        'tau1_sd_b20',\n",
    "        'tau2_sd_b20',\n",
    "        'tau3_sd_b20',\n",
    "        'chMult',\n",
    "        'neutMult',\n",
    "        'phoMult',\n",
    "        'eleMult',\n",
    "        'muMult',\n",
    "        'jetpull',\n",
    "        'labels'\n",
    "    ]\n",
    "\n",
    "\n",
    "    fromConstituentsFile = [\n",
    "        'jetconstPt_log',\n",
    "        'jetconstEta_abs',\n",
    "        'jetconstE_log',\n",
    "        'jetconstPt_Jetlog',\n",
    "        'charge',\n",
    "        'isEle',\n",
    "        'isPho',\n",
    "        'isMuon',\n",
    "        'isCh',\n",
    "        'isNh',\n",
    "        'delta_eta',\n",
    "        'delta_phi',\n",
    "        'deltaR_jet',\n",
    "        'deltaR_subjet0',\n",
    "        'deltaR_subjet1',\n",
    "        'dxy',\n",
    "        'dz'\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Draw_HistoGram(data_sig, data_bkg, feat,bins,minx,maxx, legend_loc = 'best'):\n",
    "\n",
    "    \n",
    "    tick_width = (maxx-minx)/5\n",
    "    ii = feat_all.index(feat)\n",
    "    fig, axs = plt.subplots(1, 1, tight_layout=True,figsize=(7.5,7.5))\n",
    "    data_sig = data_sig[feat]#[ind_sig].flatten()\n",
    "    data_bkg = data_bkg[feat]#[ind_bkg].flatten()\n",
    "#     data_test_sig = data_test[feat][ind_test_sig].flatten()\n",
    "#     data_test_bkg = data_test[feat][ind_test_bkg].flatten()\n",
    "    axs.hist(data_sig,\n",
    "                bins = bins,\n",
    "                histtype = 'step',\n",
    "                weights = np.ones(len(data_sig))/len(data_sig),\n",
    "                fill = True,\n",
    "                alpha = 0.55,\n",
    "                label = 'Signal',\n",
    "                log = False,\n",
    "#                density = True,\n",
    "                range = [minx,maxx],\n",
    "                hatch = '/',\n",
    "                edgecolor='k'\n",
    "                );    \n",
    "    axs.hist(data_bkg,\n",
    "                bins = bins,\n",
    "                histtype = 'step',\n",
    "                weights = np.ones(len(data_bkg))/len(data_bkg),\n",
    "                fill = True,\n",
    "                alpha = 0.55,\n",
    "                label = 'Background',\n",
    "                log = False,\n",
    "#                density = True,\n",
    "                range = [minx,maxx],\n",
    "                hatch = '\\\\',\n",
    "                edgecolor='k'\n",
    "                );\n",
    "    axs.legend(loc = legend_loc);\n",
    "    axs.set_xlim(minx,maxx)\n",
    "    axs.xaxis.set_ticks(np.arange(minx, maxx + tick_width, tick_width))\n",
    "    axs.set_xlabel('Normalized ' + feature_names[feat])\n",
    "    axs.set_ylabel('Fraction')\n",
    "\n",
    "    plt.savefig(feat + '.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data:\n",
    "Using ShowJetsData_full.npz to build the CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine QCD npz files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine Zbb npz files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if(imagesOnly):\n",
    "\n",
    "    inputfile_exts = {\n",
    "\n",
    "                  'QCD':'_addmoretaus_withbs_QCD_images.npz',\n",
    "\n",
    "                  'Zbb':'_addmoretaus_withbs_Zbb_images.npz',\n",
    "                 }\n",
    "\n",
    "else:\n",
    "    \n",
    "    inputfile_exts = {\n",
    "\n",
    "                      'QCD':'_addmoretaus_withbs_QCD_exts.npz',\n",
    "\n",
    "                      'Zbb':'_addmoretaus_withbs_Zbb_exts.npz',\n",
    "\n",
    "                     }\n",
    "\n",
    "\n",
    "\n",
    "filetypes = ['QCD','Zbb']\n",
    "\n",
    "Showjets_files = [np.load('/mnt/data/ml/ShowJetsData'+inputfile_exts[ext]) for ext in inputfile_exts.keys()]\n",
    "Constituent_files = [np.load('/mnt/data/ml/Constituent4vec'+inputfile_exts[ext]) for ext in inputfile_exts.keys()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/data/ml/ShowJetsData_addmoretaus_withbs_QCD_exts.npz\n",
      "/mnt/data/ml/ShowJetsData_addmoretaus_withbs_Zbb_exts.npz\n",
      "QCD 7436074\n",
      "Zbb 1901356\n"
     ]
    }
   ],
   "source": [
    "for ext in inputfile_exts.keys():\n",
    "    print('/mnt/data/ml/ShowJetsData'+inputfile_exts[ext])\n",
    "    \n",
    "    \n",
    "for key, file in zip(filetypes, Showjets_files):\n",
    "    print(key, file['jetMassSD'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_all = fromShowJetsFile + fromConstituentsFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dic  = {sample: {feat : data[feat]  for feat in fromConstituentsFile} for sample, data in zip(filetypes, Constituent_files)}\n",
    "data_dic2 = {sample: {feat : data[feat]  for feat in fromShowJetsFile} for sample, data in zip(filetypes, Showjets_files)}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```array([5.82069588, 5.48169994, 5.42591953, 5.42098475, 5.19779348,\n",
    "       5.19154167, 4.96679068, 4.89038801, 4.85686445, 4.84155321,\n",
    "       4.21172714, 4.03859472, 3.98107576, 3.67381763, 3.55293584,\n",
    "       3.55252504, 3.50937724, 3.46419692, 2.76884317, 2.76539183])\n",
    "       ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in data_dic.keys():\n",
    "    data_dic[key].update(data_dic2[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del Showjets_files\n",
    "del Constituent_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_data = len(data_dic['QCD']['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstSample = [key for key in data_dic.keys()][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(not imagesOnly):\n",
    "\n",
    "    dxy_min = []\n",
    "    dz_min = []\n",
    "    dxymax_min = []\n",
    "    dzmax_min = []\n",
    "\n",
    "    for key in data_dic.keys():\n",
    "\n",
    "        # Normalize tau's\n",
    "        data_dic[key]['tau1_b05'] = data_dic[key]['tau1_b05']/data_dic[key]['jetPt']\n",
    "        data_dic[key]['tau2_b05'] = data_dic[key]['tau2_b05']/data_dic[key]['jetPt']\n",
    "        data_dic[key]['tau3_b05'] = data_dic[key]['tau3_b05']/data_dic[key]['jetPt']\n",
    "        data_dic[key]['tau1_sd_b05'] = data_dic[key]['tau1_sd_b05']/data_dic[key]['jetPt']\n",
    "        data_dic[key]['tau2_sd_b05'] = data_dic[key]['tau2_sd_b05']/data_dic[key]['jetPt']\n",
    "        data_dic[key]['tau3_sd_b05'] = data_dic[key]['tau3_sd_b05']/data_dic[key]['jetPt']\n",
    "        data_dic[key]['tau1_b10'] = data_dic[key]['tau1_b10']/data_dic[key]['jetPt']\n",
    "        data_dic[key]['tau2_b10'] = data_dic[key]['tau2_b10']/data_dic[key]['jetPt']\n",
    "        data_dic[key]['tau3_b10'] = data_dic[key]['tau3_b10']/data_dic[key]['jetPt']\n",
    "        data_dic[key]['tau1_sd_b10'] = data_dic[key]['tau1_sd_b10']/data_dic[key]['jetPt']\n",
    "        data_dic[key]['tau2_sd_b10'] = data_dic[key]['tau2_sd_b10']/data_dic[key]['jetPt']\n",
    "        data_dic[key]['tau3_sd_b10'] = data_dic[key]['tau3_sd_b10']/data_dic[key]['jetPt']\n",
    "        data_dic[key]['tau1_b20'] = data_dic[key]['tau1_b20']/data_dic[key]['jetPt']\n",
    "        data_dic[key]['tau2_b20'] = data_dic[key]['tau2_b20']/data_dic[key]['jetPt']\n",
    "        data_dic[key]['tau3_b20'] = data_dic[key]['tau3_b20']/data_dic[key]['jetPt']\n",
    "        data_dic[key]['tau1_sd_b20'] = data_dic[key]['tau1_sd_b20']/data_dic[key]['jetPt']\n",
    "        data_dic[key]['tau2_sd_b20'] = data_dic[key]['tau2_sd_b20']/data_dic[key]['jetPt']\n",
    "        data_dic[key]['tau3_sd_b20'] = data_dic[key]['tau3_sd_b20']/data_dic[key]['jetPt']\n",
    "\n",
    "        # Build ratios with normalized tau's \n",
    "        \n",
    "        data_dic[key]['beta3'] = np.log( np.divide(np.multiply(np.power(data_dic[key]['tau1_b05'],2) , np.sqrt(data_dic[key]['tau2_b10'])) , data_dic[key]['tau2_b20']))     \n",
    "        data_dic[key]['beta3_sd'] = np.log(np.divide(np.divide(data_dic[key]['tau2_sd_b20'],data_dic[key]['tau1_sd_b05']),data_dic[key]['tau2_sd_b10']))\n",
    "        data_dic[key]['tau21'] = np.divide(data_dic[key]['tau2_b10'], data_dic[key]['tau1_b10'])\n",
    "\n",
    "\n",
    "        #absolute value of jetpull\n",
    "        data_dic[key]['jetpull_abs'] = np.abs(data_dic[key]['jetpull'])\n",
    "            \n",
    "            \n",
    "        # get rid of -99 from dxy and dz #\n",
    "        \n",
    "        data_dic[key]['dxy'][data_dic[key]['dxy'] == -99] = 1e-20\n",
    "        data_dic[key]['dz'][data_dic[key]['dz'] == -99] = 1e-20\n",
    "        \n",
    "        # dxy_max and dz_max take log of dxy and dz\n",
    "        data_dic[key]['dxy_max'] = np.nanmax(np.abs(data_dic[key]['dxy']), axis=1)\n",
    "        data_dic[key]['dz_max'] = np.nanmax(np.abs(data_dic[key]['dz']), axis=1)\n",
    "\n",
    "        data_dic[key]['dxy'] = np.log(np.abs(data_dic[key]['dxy']))\n",
    "        data_dic[key]['dz'] = np.log(np.abs(data_dic[key]['dz']))\n",
    "        data_dic[key]['dxy_max'] = np.log(np.abs(data_dic[key]['dxy_max']))\n",
    "        data_dic[key]['dz_max'] = np.log(np.abs(data_dic[key]['dz_max']))\n",
    "\n",
    "\n",
    "        # remove and pad -inf from log(0)\n",
    "        data_dic[key]['dxy'][np.abs(data_dic[key]['dxy']) == np.inf] = np.log(1e-20)\n",
    "        data_dic[key]['dz'][np.abs(data_dic[key]['dz']) == np.inf] = np.log(1e-20)\n",
    "        data_dic[key]['dxy_max'][np.abs(data_dic[key]['dxy_max']) == np.inf] = np.log(1e-20)\n",
    "        data_dic[key]['dz_max'][np.abs(data_dic[key]['dz_max']) == np.inf] = np.log(1e-20)\n",
    "\n",
    "        dxy_min.append(np.nanmin(data_dic[key]['dxy']))\n",
    "        dz_min.append(np.nanmin(data_dic[key]['dz']))\n",
    "        dxymax_min.append(np.nanmin(data_dic[key]['dxy']))\n",
    "        dzmax_min.append(np.nanmin(data_dic[key]['dz']))\n",
    "\n",
    "\n",
    "        # re-pad charge from -99 to -2\n",
    "        # re-pad delta variables from -99 to -1\n",
    "\n",
    "        data_dic[key]['charge'][np.abs(data_dic[key]['charge']) > 1] = -2\n",
    "        data_dic[key]['delta_eta'][data_dic[key]['delta_eta'] == -99] = -1\n",
    "        data_dic[key]['delta_phi'][data_dic[key]['delta_phi'] == -99] = -1\n",
    "        data_dic[key]['deltaR_jet'][data_dic[key]['deltaR_jet'] == -99] = -1\n",
    "        data_dic[key]['deltaR_subjet0'][data_dic[key]['deltaR_subjet0'] == -99] = -1\n",
    "        data_dic[key]['deltaR_subjet1'][data_dic[key]['deltaR_subjet1'] == -99] = -1\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Draw_HistoGram(data_dic['Zbb'], data_dic['QCD'], 'jetMassSD',50,0,500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Events with NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if(imagesOnly):\n",
    "\n",
    "    remove_nan = np.load('remove_nan.npz')\n",
    "    NaN_idx={'QCD':remove_nan['remove_nan_qcd'],\n",
    "#              'ZZ' :remove_nan['remove_nan_zz'],\n",
    "             'Zbb':remove_nan['remove_nan_zbb'],\n",
    "            }\n",
    "             \n",
    "    del remove_nan\n",
    "    \n",
    "else:\n",
    "    \n",
    "    NaN_idx={key:np.concatenate((np.argwhere(np.isnan(data_dic[key]['beta3'])), np.argwhere(np.isnan(data_dic[key]['beta3_sd'])), np.argwhere(np.isnan(data_dic[key]['dxy_max'])), np.argwhere(np.isnan(data_dic[key]['dz_max'])))).flatten() for key in data_dic.keys()}\n",
    "    np.savez('remove_nan', remove_nan_qcd = NaN_idx['QCD'], remove_nan_zbb = NaN_idx['Zbb'], )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nanv = False\n",
    "for key in data_dic.keys():\n",
    "    for feat in data_dic['QCD'].keys():\n",
    "        \n",
    "        nans = data_dic['QCD'][feat][np.isnan(data_dic['QCD'][feat])].flatten()\n",
    "        infs = data_dic['QCD'][feat][np.abs(data_dic['QCD'][feat]) == np.inf]\n",
    "        \n",
    "        if(len(infs) > 0 ):\n",
    "            print(key, feat)\n",
    "            nanv = True\n",
    "        elif(len(nans) > 0):\n",
    "            print(key, feat)\n",
    "            print(len(nans))\n",
    "            nanv = True\n",
    "\n",
    "if (not nanv):\n",
    "    print('no inf or nan values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Mass Cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if(applyMassCut):\n",
    "    \n",
    "    \n",
    "    massCut = {key: (data_dic[key]['jetMassSD'] > 50) & (data_dic[key]['jetMassSD'] < 150) for key in data_dic.keys()}\n",
    "#     massCut = {key: (data_dic[key]['jetMassSD'] > 20)  for key in data_dic.keys()}\n",
    "\n",
    "    for key in data_dic.keys():\n",
    "        massCut[key] =  np.delete(massCut[key],NaN_idx[key],0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dic['QCD']['jetMassSD'][:10][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in data_dic.keys():\n",
    "    for feat in data_dic[key].keys():\n",
    "        data_dic[key][feat] = np.delete(data_dic[key][feat],NaN_idx[key],0)\n",
    "        if(applyMassCut):\n",
    "            \n",
    "            data_dic[key][feat] = data_dic[key][feat][massCut[key]]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dic['QCD']['jetMassSD'][:10][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance and Normalize data and split into train and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build list of signal and background indices, balance them, shuffle, split to train and test and combine back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "# get signal column of label array\n",
    "ind_label = 1\n",
    "if (isZbb): ind_label = 2\n",
    "\n",
    "# split signal and background indices\n",
    "ind_zbb_inb = np.argwhere(data_dic['Zbb']['labels'][:,2] == 1)[:,0]\n",
    "ind_qcd_inb = np.argwhere(data_dic['QCD']['labels'][:,0] == 1)[:,0]\n",
    "\n",
    "print('zbb', len(ind_zbb_inb))\n",
    "print('qcd', len(ind_qcd_inb))\n",
    "\n",
    "# cut off data at size of smallest sample\n",
    "len_data = np.min((len(ind_qcd_inb), len(ind_zbb_inb)))\n",
    "\n",
    "print(len_data)\n",
    "\n",
    "ind_zbb = ind_zbb_inb[:len_data]\n",
    "ind_qcd = ind_qcd_inb[:len_data]\n",
    "\n",
    "\n",
    "# split into train and test indices\n",
    "cut = int(split*len_data)\n",
    "ind_train = {'QCD':ind_qcd[:cut],\n",
    "             'Zbb':ind_zbb[:cut]\n",
    "            }\n",
    "ind_test = {'QCD':ind_qcd[cut:],\n",
    "             'Zbb':ind_zbb[cut:]\n",
    "            }\n",
    "\n",
    "\n",
    "for key in ind_train.keys():\n",
    "    ind_train[key] = ind_train[key]\n",
    "    ind_test[key] = ind_test[key]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dic['QCD']['jetMassSD'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ind_qcd))\n",
    "# print(len(ind_zz))\n",
    "print(len(ind_zbb))\n",
    "\n",
    "print('N train', len(ind_train['QCD']))\n",
    "print('N test', len(ind_test['QCD']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dic['QCD']['jetMassSD'][:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Unscaled Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = ['jetconstPt_log',\n",
    " 'jetconstEta_abs',\n",
    " 'jetconstE_log',\n",
    " 'jetconstPt_Jetlog',\n",
    " 'jetMass',\n",
    " 'jetMassSD',\n",
    " 'deltaR_subjets',\n",
    " 'jetPt',\n",
    " 'z',\n",
    " 'tau1_b05',\n",
    " 'tau2_b05',\n",
    " 'tau3_b05',\n",
    " 'tau1_sd_b05',\n",
    " 'tau2_sd_b05',\n",
    " 'tau3_sd_b05',\n",
    " 'tau1_b10',\n",
    " 'tau2_b10',\n",
    " 'tau3_b10',\n",
    " 'tau1_sd_b10',\n",
    " 'tau2_sd_b10',\n",
    " 'tau3_sd_b10',\n",
    " 'tau1_b15',\n",
    " 'tau2_b15',\n",
    " 'tau3_b15',\n",
    " 'tau1_sd_b15',\n",
    " 'tau2_sd_b15',\n",
    " 'tau3_sd_b15',\n",
    " 'tau1_b20',\n",
    " 'tau2_b20',\n",
    " 'tau3_b20',\n",
    " 'tau1_sd_b20',\n",
    " 'tau2_sd_b20',\n",
    " 'tau3_sd_b20',\n",
    " 'delta_eta',\n",
    " 'delta_phi',\n",
    " 'deltaR_jet',\n",
    " 'deltaR_subjet0',\n",
    " 'deltaR_subjet1',\n",
    " 'jetpull',\n",
    " 'dxy',\n",
    " 'dz',\n",
    " 'jetImages',\n",
    " 'jetEta',\n",
    " 'jetPhi',\n",
    " 'chMult',\n",
    " 'neutMult',\n",
    " 'phoMult',\n",
    " 'eleMult',\n",
    " 'muMult',\n",
    " 'beta3',\n",
    " 'beta3_sd',\n",
    " 'tau21',\n",
    " 'jetpull_abs',\n",
    " 'dxy_max',\n",
    " 'dz_max',\n",
    " 'charge',\n",
    "       ]\n",
    "\n",
    "# norm = []\n",
    "\n",
    "stand = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build two dictionaries with train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#THIS CODE SETS ALL VALUES OUTSIDE OF 3 SIGMA RANGE TO THE LAST ALLOWED BIN\n",
    "\n",
    "# ZZ has been removed \n",
    "\n",
    "\n",
    "for feat in data_dic['QCD'].keys():\n",
    "    for key in data_dic.keys():\n",
    "        if feat in ['jetImages', 'labels']:\n",
    "            continue\n",
    "        elif 'is' in feat:\n",
    "            continue\n",
    "        elif ('dxy' in feat) or ('dz' in feat):\n",
    "            continue\n",
    "        else:\n",
    "            #print(feat)\n",
    "            if(key==firstSample):\n",
    "                std = np.std(np.concatenate((data_dic['QCD'][feat], data_dic['Zbb'][feat]), axis=0).flatten())\n",
    "                mean = np.mean(np.concatenate((data_dic['QCD'][feat], data_dic['Zbb'][feat]), axis=0).flatten())\n",
    "            data_dic[key][feat][data_dic[key][feat] > mean + 3 * std] = mean + 3 * std\n",
    "            data_dic[key][feat][data_dic[key][feat] < mean - 3 * std] = mean - 3 * std\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dic['QCD']['jetMassSD'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum = {}\n",
    "maximum = {}\n",
    "for feat in data_dic['QCD'].keys():\n",
    "    \n",
    "    print(feat)\n",
    "    \n",
    "    if( not 'jetImages' in feat):\n",
    "        \n",
    "       \n",
    "\n",
    "        minimum[feat] = np.min(np.concatenate([data_dic['QCD'][feat], data_dic['Zbb'][feat]], axis=0).flatten())\n",
    "        maximum[feat] = np.max(np.concatenate([data_dic['QCD'][feat], data_dic['Zbb'][feat]], axis=0).flatten())\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dic['QCD']['jetMassSD'][:10]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_train = {'QCD':{},\n",
    "             'ZZ':{},\n",
    "             'Zbb':{},}\n",
    "data_test = {'QCD':{},\n",
    "            'ZZ':{},\n",
    "            'Zbb':{},}\n",
    "\n",
    "for feat in data_dic['QCD'].keys():\n",
    "    \n",
    "    sub_train = {key: data_dic[key][feat][ind_train[key]] for key in data_dic.keys()}\n",
    "    sub_test = {key: data_dic[key][feat][ind_test[key]] for key in data_dic.keys()}\n",
    "\n",
    "    for key in data_dic.keys():\n",
    "        if feat == 'jetImages':\n",
    "#             if(key==firstSample):\n",
    "#                 minn = np.min(np.concatenate((sub_train['QCD'],sub_test['QCD'],sub_train['ZZ'],sub_test['ZZ'],sub_train['Zbb'],sub_test['Zbb']),axis=0))\n",
    "#                 maxx = np.max(np.concatenate((sub_train['QCD'],sub_test['QCD'],sub_train['ZZ'],sub_test['ZZ'],sub_train['Zbb'],sub_test['Zbb']),axis=0))\n",
    "                \n",
    "            minn = np.min([np.min(sub_train['QCD'], axis = 0), np.min(sub_test['QCD'], axis = 0), np.min(sub_train['Zbb'], axis = 0), np.min(sub_test['Zbb'], axis = 0)], axis=0)\n",
    "            maxx = np.max([np.max(sub_train['QCD'], axis = 0), np.max(sub_test['QCD'], axis = 0), np.max(sub_train['Zbb'], axis = 0), np.max(sub_test['Zbb'], axis = 0)], axis=0)\n",
    "\n",
    "#             minn = minimum[feat]\n",
    "#             maxx = maximum[feat]\n",
    "                \n",
    "            data_train[key][feat] = (sub_test[key]-minn)/(maxx-minn)\n",
    "            data_test[key][feat] = (sub_test[key]-minn)/(maxx-minn)\n",
    "        elif feat in norm:\n",
    "#             if(key==firstSample):\n",
    "#                 minn = np.min(np.concatenate((sub_train['QCD'],sub_test['QCD'],sub_train['ZZ'],sub_test['ZZ'],sub_train['Zbb'],sub_test['Zbb']),axis=0).flatten(),axis=0)\n",
    "#                 maxx = np.max(np.concatenate((sub_train['QCD'],sub_test['QCD'],sub_train['ZZ'],sub_test['ZZ'],sub_train['Zbb'],sub_test['Zbb']),axis=0).flatten(),axis=0)\n",
    "#                 minn = np.min([np.min(sub_train['QCD'], axis = 0), np.min(sub_test['QCD'], axis = 0), np.min(sub_train['ZZ'], axis = 0), np.min(sub_test['ZZ'], axis = 0), np.min(sub_train['Zbb'], axis = 0), np.min(sub_test['Zbb'], axis = 0)], axis=0)\n",
    "#                 maxx = np.max([np.max(sub_train['QCD'], axis = 0), np.max(sub_test['QCD'], axis = 0), np.max(sub_train['ZZ'], axis = 0), np.max(sub_test['ZZ'], axis = 0), np.max(sub_train['Zbb'], axis = 0), np.max(sub_test['Zbb'], axis = 0)], axis=0)\n",
    "\n",
    "            minn = minimum[feat]\n",
    "            maxx = maximum[feat]\n",
    "        \n",
    "            print(feat, key, np.max(sub_test[key].flatten()))\n",
    "            print(feat, key, np.max((sub_test[key]-minn)/(maxx-minn)))\n",
    "                \n",
    "            data_train[key][feat] = (sub_train[key]-minn)/(maxx-minn)\n",
    "            data_test[key][feat] = (sub_test[key]-minn)/(maxx-minn)\n",
    "        elif feat in stand:\n",
    "            mu = np.mean(np.concatenate((sub_train['QCD'],sub_test['QCD'],sub_train['ZZ'],sub_test['ZZ'],sub_train['Zbb'],sub_test['Zbb']),axis=0).flatten(),axis=0)\n",
    "            std = np.std(np.concatenate((sub_train['QCD'],sub_test['QCD'],sub_train['ZZ'],sub_test['ZZ'],sub_train['Zbb'],sub_test['Zbb']),axis=0).flatten(),axis=0)\n",
    "            data_train[key][feat] = (sub_train[key]-mu)/std\n",
    "            data_test[key][feat] = (sub_test[key]-mu)/std\n",
    "        else:\n",
    "            data_train[key][feat] = sub_train[key]\n",
    "            data_test[key][feat] = sub_test[key]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dic['QCD']['jetMassSD'][:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_train = len(data_train['QCD']['labels'])\n",
    "print(n_train)\n",
    "n_test = len(data_test['QCD']['labels'])\n",
    "print(n_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots to Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dxy for rescaled QCD and Zbb between 0.15 and 0.2\n",
    "```\n",
    "print(data_test['QCD']['dxy_max'][(data_test['QCD']['dxy_max'] < 0.2) & (data_test['QCD']['dxy_max'] > 0.15)].shape)\n",
    "print(data_test['Zbb']['dxy_max'][(data_test['Zbb']['dxy_max'] < 0.2) & (data_test['Zbb']['dxy_max'] > 0.15)].shape)\n",
    "```\n",
    "\n",
    "```\n",
    "(3096,)\n",
    "(0,)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qcd_file = np.load('/mnt/data/ml/Constituent4vec_addmoretaus_QCD.npz')\n",
    "\n",
    "# zz_file = np.load('/mnt/data/ml/Constituent4vec_addmoretaus_Zbb.npz')\n",
    "\n",
    "\n",
    "# qcd_dxy = qcd_file['dxy']\n",
    "# zz_dxy = zz_file['dxy']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zz_dxy_cut = zz_dxy[zz_dxy > 0].flatten()\n",
    "# qcd_dxy_cut = qcd_dxy[qcd_dxy > 0].flatten()\n",
    "\n",
    "# zz_max = np.max(zz_dxy, axis=1)\n",
    "# qcd_max = np.max(qcd_dxy, axis=1)\n",
    "\n",
    "# zz_max = zz_max[zz_max > 0]\n",
    "# qcd_max = qcd_max[qcd_max > 0]\n",
    "\n",
    "# plt.hist(np.log10(np.abs(zz_dxy_cut)), bins=50, alpha=0.5, label='ZZ=bb')\n",
    "# plt.hist(np.log10(np.abs(qcd_dxy_cut)), bins=50, alpha=0.5, label='QCD')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# plt.hist(np.log10(np.abs(zz_max)), bins=50, alpha=0.5, label='Zbb')\n",
    "# plt.hist(np.log10(np.abs(qcd_max)), bins=50, alpha=0.5, label='QCD')\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.min(np.log10(np.abs(zz_dxy_cut))))\n",
    "# print(np.max(np.log10(np.abs(zz_dxy_cut))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recreating labels separately in np.savez because labels in data dictionaries are not floats\n",
    "\n",
    "train_labs = {'QCD': np.array(np.vstack((np.ones(n_train), np.zeros(n_train), np.zeros(n_train))).T, dtype=float),\n",
    "#              'ZZ':  np.array(np.vstack((np.zeros(n_train), np.ones(n_train), np.zeros(n_train))).T, dtype=float),\n",
    "             'Zbb': np.array(np.vstack((np.zeros(n_train), np.zeros(n_train), np.ones(n_train))).T, dtype=float),\n",
    "            }\n",
    "test_labs = {'QCD': np.array(np.vstack((np.ones(n_test), np.zeros(n_test), np.zeros(n_test))).T, dtype=float),\n",
    "#               'ZZ':  np.array(np.vstack((np.zeros(n_test), np.ones(n_test), np.zeros(n_test))).T, dtype=float),\n",
    "              'Zbb': np.array(np.vstack((np.zeros(n_test), np.zeros(n_test), np.ones(n_test))).T, dtype=float),\n",
    "            }\n",
    "\n",
    "\n",
    "# for key in data_train.keys():\n",
    "# for key in ['Z/bb']:\n",
    "data_train['QCD'].pop('labels')\n",
    "data_test['QCD'].pop('labels')\n",
    "data_train['Zbb'].pop('labels')\n",
    "data_test['Zbb'].pop('labels')\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_train['Zbb']['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save training and testing QCD, ZZ, and Zbb dictionaries to separate npz files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = '/mnt/data/ml/PreProcessing/check/'\n",
    "# ext = ''\n",
    "ext = '_exts'\n",
    "\n",
    "if(imagesOnly):\n",
    "    ext = ext+'_images'\n",
    "\n",
    "if(applyMassCut):\n",
    "    ext = '_msd50to150'\n",
    "#     ext = ext+'_msd20'\n",
    "\n",
    "ext = ext+'_v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(loc+'ShowJets_train_QCD'+ext, **data_train['QCD'], labels = train_labs['QCD'])\n",
    "np.savez(loc+'ShowJets_test_QCD'+ext, **data_test['QCD'], labels = test_labs['QCD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savez(loc+'ShowJets_train_ZZ'+ext,**data_train['ZZ'], labels = train_labs['ZZ'])\n",
    "# np.savez(loc+'ShowJets_test_ZZ'+ext,**data_test['ZZ'], labels = test_labs['ZZ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(loc+'ShowJets_train_Zbb'+ext,**data_train['Zbb'], labels = train_labs['Zbb'])\n",
    "np.savez(loc+'ShowJets_test_Zbb'+ext,**data_test['Zbb'], labels = test_labs['Zbb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endtime = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = endtime - starttime\n",
    "print('Elapsed Time: {0:0.1f} min {1:0.2f} sec'.format(delta // 60, delta % 3600 % 60))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xaugs = [ 'jetMass',\n",
    "          'jetMassSD',\n",
    "          'deltaR_subjets',\n",
    "          'z',\n",
    "          'tau1_b05',\n",
    "          'tau2_b05',\n",
    "          'tau3_b05',\n",
    "          'tau1_sd_b05',\n",
    "          'tau2_sd_b05',\n",
    "          'tau3_sd_b05',\n",
    "          'tau1_b10',\n",
    "          'tau2_b10',\n",
    "          'tau3_b10',\n",
    "          'tau1_sd_b10',\n",
    "          'tau2_sd_b10',\n",
    "          'tau3_sd_b10',\n",
    "          'tau1_b15',\n",
    "          'tau2_b15',\n",
    "          'tau3_b15',\n",
    "          'tau1_sd_b15',\n",
    "          'tau2_sd_b15',\n",
    "          'tau3_sd_b15',\n",
    "          'tau1_b20',\n",
    "          'tau2_b20',\n",
    "          'tau3_b20',\n",
    "          'tau1_sd_b20',\n",
    "          'tau2_sd_b20',\n",
    "          'tau3_sd_b20',\n",
    "          'jetpull',\n",
    "          'chMult',\n",
    "          'neutMult',\n",
    "          'phoMult',\n",
    "          'eleMult',\n",
    "          'muMult',\n",
    "          'beta3',\n",
    "          'beta3_sd',\n",
    "          'tau21',\n",
    "          'dxy_max',\n",
    "         'dz_max',\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_corr = {feat: data_train['QCD'][feat].flatten() for feat in xaugs}\n",
    "data_test_corr =  {feat: data_test['QCD'][feat].flatten() for feat in xaugs}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(data_train_corr,columns=xaugs)\n",
    "df_test = pd.DataFrame(data_test_corr,columns=xaugs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrMat_train = df_train.corr()\n",
    "corrMat_test = df_test.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrMat_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrMat_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JetImages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lrth /mnt/data/ml/PreProcessing/check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls -lrth /mnt/data/ml/PreProcessing\n",
    "\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(test_zz['jetImages'].shape)\n",
    "\n",
    "# print(test_qcd['jetImages'].shape)\n",
    "\n",
    "\n",
    "\n",
    "print(np.sum(data_test['QCD']['jetImages']))\n",
    "print(np.sum(data_test['ZZ']['jetImages']))\n",
    "print(np.sum(data_test['Zbb']['jetImages']))\n",
    "\n",
    "\n",
    "print(data_test['QCD']['jetImages'].shape)\n",
    "print(data_test['ZZ']['jetImages'] .shape)\n",
    "print(data_test['Zbb']['jetImages'].shape)\n",
    "\n",
    "\n",
    "print(data_train['QCD']['jetImages'].shape)\n",
    "print(data_train['ZZ']['jetImages'] .shape)\n",
    "print(data_train['Zbb']['jetMassSD'].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Save images dimensions\n",
    "grid = len(data_dic['QCD']['jetImages'][0])\n",
    "\n",
    "#plot train and test signal\n",
    "sig_train_images = np.sum(data_train['ZZ']['jetImages'],axis=0).reshape(grid,grid)\n",
    "sig_test_images = np.sum(data_test['ZZ']['jetImages'],axis=0).reshape(grid,grid)\n",
    "bkg_train_images = np.sum(data_train['QCD']['jetImages'],axis=0).reshape(grid,grid)\n",
    "bkg_test_images = np.sum(data_test['QCD']['jetImages'],axis=0).reshape(grid,grid)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "vmin=1\n",
    "vmax=100000\n",
    "\n",
    "extent_sig = [-sig_test_images.shape[1]/2., sig_test_images.shape[1]/2., -sig_test_images.shape[0]/2., sig_test_images.shape[0]/2. ]\n",
    "extent_bkg = [-bkg_test_images.shape[1]/2., bkg_test_images.shape[1]/2., -bkg_test_images.shape[0]/2., bkg_test_images.shape[0]/2. ]\n",
    "\n",
    "\n",
    "\n",
    "# Build figure with train and test set \n",
    "fig = plt.figure(figsize = (12.5,8))\n",
    "ax1 = fig.add_subplot(121)\n",
    "im0 = ax1.imshow(sig_test_images,\n",
    "                      interpolation='nearest',\n",
    "#                      origin='low',\n",
    "                      cmap = 'Greens',\n",
    "                      norm=LogNorm(),\n",
    "                     vmin = vmin,\n",
    "                     vmax = vmax,\n",
    "                      extent = extent_sig)\n",
    "ax1.set_title('Signal Images')\n",
    "fig.colorbar(im0,\n",
    "             fraction=0.0467, pad=0.02,\n",
    "             ax=ax1)\n",
    "im1 = ax[1][0].imshow(sig_test_images,\n",
    "                      interpolation='nearest',\n",
    "                      origin='low',\n",
    "                      cmap = 'Greens',\n",
    "                      norm=LogNorm(),\n",
    "                     vmin = 1,\n",
    "                     vmax = 20000)\n",
    "ax[1][0].set_title('Test Signal Images')\n",
    "fig.colorbar(im1,shrink=0.8, ax=ax[1][0])\n",
    "ax2 = fig.add_subplot(122)\n",
    "im2 = ax2.imshow(bkg_test_images,\n",
    "                      interpolation='nearest',\n",
    "#                      origin='low',\n",
    "                      cmap = 'Greens',\n",
    "                      norm=LogNorm(),\n",
    "                     vmin = vmin,\n",
    "                     vmax = vmax,\n",
    "                      extent = extent_bkg)\n",
    "ax2.set_title('Background Images')\n",
    "fig.colorbar(im2,\n",
    "             fraction=0.0467, pad=0.02,\n",
    "             ax=ax2)\n",
    "im3 = ax[1][1].imshow(bkg_test_images,\n",
    "                      interpolation='nearest',\n",
    "                      origin='low',\n",
    "                      cmap = 'Greens',\n",
    "                      norm=LogNorm(),\n",
    "                     vmin = 1,\n",
    "                     vmax = 20000)\n",
    "ax[1][1].set_title('Test Background Images')\n",
    "fig.colorbar(im3,shrink=0.8, ax=ax[1][1])\n",
    "plt.show()\n",
    "plt.savefig('plots/histogram/jet_images.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rows = int(np.ceil(len(test_qcd.keys()) / 3))\n",
    "\n",
    "fig, axes = plt.subplots(nrows=rows, ncols=3, figsize=(15, 3.5*rows))\n",
    "\n",
    "row = 0\n",
    "col = 0\n",
    "\n",
    "signal = 'ZZ'\n",
    "\n",
    "print('Plotting .', end='')\n",
    "\n",
    "for name in test_qcd.keys():\n",
    "    \n",
    "    if('labels' in name): continue\n",
    "        \n",
    "\n",
    "\n",
    "    if(rows < 2):\n",
    "        ax = axes[col]\n",
    "    else:\n",
    "        ax = axes[row][col]\n",
    "        \n",
    "    ax.hist(test_zz[name].flatten(), bins=np.linspace(0,1.05,20), alpha=0.5, density=True, label=signal)\n",
    "    ax.hist(test_qcd[name].flatten(), bins=np.linspace(0,1.05,20), alpha=0.5, density=True, label='QCD')\n",
    "\n",
    "\n",
    "    ax.set_xlabel(name)\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.legend()\n",
    "    #ax.set_yscale('log')\n",
    "\n",
    "\n",
    "    col += 1\n",
    "    if(col > 2):\n",
    "        col=0\n",
    "        row += 1\n",
    "\n",
    "    print('.', end='')\n",
    "    \n",
    "    \n",
    "plt.subplots_adjust(hspace=0.35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
