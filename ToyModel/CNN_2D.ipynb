{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "import keras.backend\n",
    "from keras.layers import Input, Conv2D, MaxPool2D, Flatten, Dense, BatchNormalization, Dropout\n",
    "from keras import models\n",
    "import keras.utils\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import math\n",
    "import time\n",
    "import h5py\n",
    "import sklearn\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data:\n",
    "Using jetImages_signal.npz and jetImages_bkg.npz to train the neural network and using jetImages_signal_test.npz and jetImages_bkg_test.npz for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = 16\n",
    "data_train = np.load('data/jetImagesTrain1.npz')\n",
    "data_test = np.load('data/jetImagesTest1.npz')\n",
    "feat_all = [key for key in data_train.keys()]\n",
    "feat_all.remove('labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build DNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    input1 = layers.Input(shape = (grid, grid, 1), name = 'input')\n",
    "    x = layers.Conv2D(32, (5, 5), activation='relu', name = \"conv1\", padding = 'same')(input1)\n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu', name = 'conv2', padding = 'same')(x)\n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu', name = 'conv3', padding = 'same')(x)\n",
    "    x = layers.MaxPool2D((2, 2), name = 'maxpool1')(x)\n",
    "    x = layers.Flatten(name = 'flatten')(x)\n",
    "    x = layers.Dense(64, activation='relu', name = 'dense1')(x)\n",
    "    output = layers.Dense(2, activation='softmax', name = 'output')(x)\n",
    "    model = models.Model(inputs= [input1],\n",
    "                         outputs = output)\n",
    "    opt=keras.optimizers.Adam(lr=0.001,beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                optimizer=opt,\n",
    "                metrics=['binary_crossentropy', 'accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_XY(features,label,dic):\n",
    "    X = [dic[key] for key in features]\n",
    "    Y = [dic[key] for key in label]\n",
    "    return X,Y\n",
    "features = ['jetImages']\n",
    "X_train, Y_train = build_XY(features,['labels'],data_train)\n",
    "X_test, Y_test = build_XY(features,['labels'],data_test)\n",
    "# CNN = build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test model's prediction $before$ training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_batch = [ele[:10] for ele in X_train]\n",
    "# Y_batch = [ele[:10] for ele in Y_train]\n",
    "# example_result = CNN.predict(x = X_batch)\n",
    "# results = CNN.evaluate(x = X_batch, y = Y_batch )\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_batch = [ele for ele in X_train]\n",
    "# Y_batch = [ele for ele in Y_train]\n",
    "# X_batch_test = [ele for ele in X_test]\n",
    "# Y_batch_test = [ele for ele in Y_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now train! (warning: if building CNN, computer tends to get loud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not os.path.exists(\"model\"):\n",
    "#     os.mkdir(\"model\")\n",
    "# checkpoint_path = \"model/CNN2D_3.h5\"\n",
    "# model_checkpoint = keras.callbacks.ModelCheckpoint(checkpoint_path, monitor='val_loss', \n",
    "#                                    verbose=1, save_best_only=True, \n",
    "#                                    save_weights_only=False, mode='auto', \n",
    "#                                    period=1)    \n",
    "# EPOCHS = 100\n",
    "# early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "# history = CNN.fit(\n",
    "#   X_batch, Y_batch,\n",
    "#   epochs=EPOCHS, validation_split = 0.2, verbose = 0,\n",
    "#   callbacks=[early_stop, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_history(history):\n",
    "#     hist = pd.DataFrame(history.history)\n",
    "#     print(hist.keys())\n",
    "#     hist['epoch'] = history.epoch\n",
    "#     plt.figure()\n",
    "#     plt.xlabel('Epoch')\n",
    "#     plt.ylabel('Loss')\n",
    "#     plt.plot(hist['epoch'], hist['loss'],\n",
    "#            label='Train Error')\n",
    "#     plt.plot(hist['epoch'], hist['val_loss'],\n",
    "#            label = 'Val Error')\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "\n",
    "# plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load best weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 16, 16, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 16, 16, 32)        832       \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "maxpool1 (MaxPooling2D)      (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense1 (Dense)               (None, 64)                131136    \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 150,594\n",
      "Trainable params: 150,594\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model = keras.models.load_model('model/CNN2D_3.h5')\n",
    "best_model.summary()\n",
    "# results = best_model.evaluate(X_batch_test, Y_batch_test, verbose = 0)\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the performance of our DNN! Plot predictions vs. true values (the line is predictions vs. predicitons)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot ROC\n",
    "# predict = best_model.predict(X_batch_test)\n",
    "# from sklearn.metrics import roc_curve, auc\n",
    "# fpr, tpr, thresholds = roc_curve(Y_batch_test[0][:,1], predict[:,1])\n",
    "# roc_auc = auc(fpr, tpr)\n",
    "# plt.plot(fpr, tpr, lw=4, color='b', label='auc = %.3f' % (roc_auc))\n",
    "# plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='k', label='random chance')\n",
    "# plt.xlim([0, 1.0])\n",
    "# plt.ylim([0, 1.0])\n",
    "# plt.xlabel('false positive rate')\n",
    "# plt.ylabel('true positive rate')\n",
    "# plt.title('Toy 2D CNN ROC')\n",
    "# plt.legend(loc=\"lower right\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sig_pred = predict[np.argwhere(Y_batch_test[0][:][:,1].squeeze()==1.)].squeeze()\n",
    "# bkg_pred = predict[np.argwhere(Y_batch_test[0][:][:,1].squeeze()==0.)].squeeze()\n",
    "# plt.hist([sig_pred[:,1], bkg_pred[:,1]],\n",
    "#          color = ['blue', 'red'], histtype = 'step', label = ['signal predictions', 'background predictions'])\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    input1 = layers.Input(shape = (grid, grid, 1))\n",
    "    input2 = [layers.Input(shape = (1,)) for i in range(1,5)]\n",
    "    x = layers.Conv2D(32, (5, 5), activation='relu', name = \"conv1\", padding = 'same')(input1)\n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu', name = 'conv2', padding = 'same')(x)\n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu', name = 'conv3', padding = 'same')(x)\n",
    "    x = layers.MaxPool2D((2, 2), name = 'maxpool1')(x)\n",
    "    x1 = layers.Flatten()(x)\n",
    "    x = layers.concatenate(inputs = [x1] + input2, axis = -1)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    output = layers.Dense(2, activation='softmax')(x)\n",
    "    model = models.Model(inputs= [input1] + input2,\n",
    "                         outputs = output)\n",
    "    opt=keras.optimizers.Adam(lr=0.001,beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                optimizer=opt,\n",
    "                metrics=['binary_crossentropy', 'accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000,)\n"
     ]
    }
   ],
   "source": [
    "features = [key for key in data_train.keys()];features.remove('labels');features\n",
    "X_train, Y_train = build_XY(features,['labels'],data_train)\n",
    "print(X_train[1].shape)\n",
    "X_test, Y_test = build_XY(features,['labels'],data_test)\n",
    "CNN_XAUG = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 16, 16, 1)\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "[0.6931425333023071, 0.6931425333023071, 0.6000000238418579]\n"
     ]
    }
   ],
   "source": [
    "X_batch = [ele[:10] for ele in X_train]\n",
    "print(X_batch[0].shape)\n",
    "Y_batch = [ele[:10] for ele in Y_train]\n",
    "example_result = CNN_XAUG.predict(x = X_batch)\n",
    "results = CNN_XAUG.evaluate(x = X_batch, y = Y_batch )\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batch = [ele for ele in X_train]\n",
    "Y_batch = [ele for ele in Y_train]\n",
    "X_batch_test = [ele for ele in X_test]\n",
    "Y_batch_test = [ele for ele in Y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00865, saving model to model/CNN2D_XAUG_2.h5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.00865 to 0.00662, saving model to model/CNN2D_XAUG_2.h5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00662 to 0.00638, saving model to model/CNN2D_XAUG_2.h5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00638 to 0.00635, saving model to model/CNN2D_XAUG_2.h5\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00635 to 0.00607, saving model to model/CNN2D_XAUG_2.h5\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00607\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00607\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00607\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.00607\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00607\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"model/CNN2D_XAUG_2.h5\"\n",
    "model_checkpoint = keras.callbacks.ModelCheckpoint(checkpoint_path, monitor='val_loss', \n",
    "                                   verbose=1, save_best_only=True, \n",
    "                                   save_weights_only=False, mode='auto', \n",
    "                                   period=1)    \n",
    "EPOCHS = 1000\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, min_delta=1.0e-5)\n",
    "history = CNN_XAUG.fit(\n",
    "  X_batch, Y_batch,\n",
    "  epochs=EPOCHS, validation_split = 0.2, verbose = 0,\n",
    "  callbacks=[early_stop, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['val_loss', 'val_binary_crossentropy', 'val_acc', 'loss',\n",
      "       'binary_crossentropy', 'acc'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_history(history):\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    print(hist.keys())\n",
    "    hist['epoch'] = history.epoch\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.plot(hist['epoch'], hist['loss'],\n",
    "           label='Train Error')\n",
    "    plt.plot(hist['epoch'], hist['val_loss'],\n",
    "           label = 'Val Error')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 16, 16, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 16, 16, 32)   832         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 16, 16, 32)   9248        conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3 (Conv2D)                  (None, 16, 16, 32)   9248        conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "maxpool1 (MaxPooling2D)         (None, 8, 8, 32)     0           conv3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 2048)         0           maxpool1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 2052)         0           flatten_1[0][0]                  \n",
      "                                                                 input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           131392      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          8320        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2)            258         dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 159,298\n",
      "Trainable params: 159,298\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 4 array(s), but instead got the following list of 5 arrays: [array([[[[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n    ...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-cd72b129f47a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model/CNN2D_XAUG.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_batch_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1102\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Prepare inputs, delegate logic to `test_loop`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0;34m'Expected to see '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' array(s), '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0;34m'but instead got the following list of '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m                 str(len(data)) + ' arrays: ' + str(data)[:200] + '...')\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             raise ValueError(\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 4 array(s), but instead got the following list of 5 arrays: [array([[[[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n    ..."
     ]
    }
   ],
   "source": [
    "best_model = keras.models.load_model('model/CNN2D_XAUG.h5')\n",
    "best_model.summary()\n",
    "results = best_model.evaluate(X_batch_test, Y_batch_test[0], verbose = 0)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC\n",
    "predict = best_model.predict(X_batch_test)\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, thresholds = roc_curve(Y_batch_test[0][:][:,1], predict[:][:,1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, lw=4, color='b', label='auc = %.3f' % (roc_auc))\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='k', label='random chance')\n",
    "plt.xlim([0, 1.0])\n",
    "plt.ylim([0, 1.0])\n",
    "plt.xlabel('false positive rate')\n",
    "plt.ylabel('true positive rate')\n",
    "plt.title('Toy 2D CNN ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_pred = predict[np.argwhere(Y_batch_test[0][:,1].squeeze()==1.)].squeeze()\n",
    "print(sig_pred)\n",
    "bkg_pred = predict[np.argwhere(Y_batch_test[0][:,1].squeeze()==0.)].squeeze()\n",
    "plt.hist([sig_pred[:,1], bkg_pred[:,1]],\n",
    "         color = ['blue', 'red'], histtype = 'step', label = ['signal predictions', 'background predictions'])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
